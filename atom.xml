<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>welcome</title>
  
  <subtitle>Tensor Robotics</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.tensor-robotics.com/"/>
  <updated>2020-07-06T08:23:58.592Z</updated>
  <id>http://blog.tensor-robotics.com/</id>
  
  <author>
    <name>chopin1998@gmail.com</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>毫米波雷达 第五篇</title>
    <link href="http://blog.tensor-robotics.com/archives/d7992bd.html"/>
    <id>http://blog.tensor-robotics.com/archives/d7992bd.html</id>
    <published>2020-07-06T13:51:14.000Z</published>
    <updated>2020-07-06T08:23:58.592Z</updated>
    
    <content type="html"><![CDATA[<h1 id="在LinuX环境下配置TI毫米波雷达开发环境"><a href="#在LinuX环境下配置TI毫米波雷达开发环境" class="headerlink" title="在LinuX环境下配置TI毫米波雷达开发环境"></a>在LinuX环境下配置TI毫米波雷达开发环境</h1><h2 id="从Debian到Ubuntu"><a href="#从Debian到Ubuntu" class="headerlink" title="从Debian到Ubuntu"></a>从Debian到Ubuntu</h2><p>本来已经在Debian下工作得不错，不过最近因为要学习ROS，居然把用了十多年的Debian给换成了Ubuntu。。。。。</p><p>虽然是大厂出品，但其中还有一些小坑。</p><p>只好再次重新安装配置一次，权当记录。</p><p>目前的版本是Ubuntu 20.04（focal）</p><hr><h2 id="从官方网站下载文件"><a href="#从官方网站下载文件" class="headerlink" title="从官方网站下载文件"></a>从官方网站下载文件</h2><ul><li>CCS10.0.0.00010_linux-x64.tar.gz</li><li>mmwave_sdk_03_04_00_03-Linux-x86-Install.bin</li><li>uniflash_sl.6.0.0.2710.run</li></ul><p><strong>CCS</strong>是TI的IDE，其实就是老派电子厂家最爱用的魔改eclipse……</p><p><strong>mmwave_sd</strong>k则包含了毫米波雷达内建DSP的工具链、中间件等</p><p><strong>uniflash</strong>则是TI专门给IWR/AWR系列器件提供的下载程序</p><hr><h2 id="CCS10"><a href="#CCS10" class="headerlink" title="CCS10"></a>CCS10</h2><p>安装CCS10前，需要首先下载这些包<br>libc6:i386 libusb-0.1 libgconf libncurses5 libpython2.7 libtinfo5</p><p>注意，需要i386版本，因此如果系统原先没有安装过，需要</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg --add-architecture i386</span><br></pre></td></tr></tbody></table></figure><p>然后解压CCS10.xxxxxx.tar.gz，运行其中的<strong>ccs_setup_10.0.0.00010.run</strong>, 弹出安装GUI</p><p>一路点击next， 选择安装路径什么的，直到器件选择。</p><p><img src="d7992bd/install_device_choose.png" alt="全部安装会超过4G空间，可以根据需要选择，这里就只安装mmWave系列"></p><p>后面再点几次next之后就是自动复制文件的过程。</p><p>等着就好。</p><p>提示一下，最好设置一个好一点儿代理，国内下载速度，你懂的。。</p><p>进入后，可以在[view]-&gt;[Resource Explorer]里选择下载对应的Toolbox，包含了更多examples和配置工具。</p><hr><h2 id="SDK"><a href="#SDK" class="headerlink" title="SDK"></a>SDK</h2><p>不管怎么说，需要感谢TI所做的努力，可以在linux下相对完整得开发毫米波雷达器件。</p><p>直接运行mmwave_sdk_03_04_xxxxxxx-Install.bin，弹出GUI安装对话框，选择安装路径，自动解压复制。</p><p>完了之后，还需要运行</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install mono-complete</span><br></pre></td></tr></tbody></table></figure><p>为什么需要整套c#环境呢？因为<a href="/archives/62e757fa.html" title="如前文所述">如前文所述</a>, 器件内部有两个可编程逻辑块，需要分别写程序和编译，最后打包成一个bin文件供下载程序下载。</p><p>TI的这个打包过程分了至少四步骤，每个步骤都有对应的二进制程序。</p><p>TI为<strong>几乎</strong>每个二进制程序提供了windows的exe, 和Linux的32bit elf， 除了一个例外……</p><p>这个例外就是<strong>out2rprc</strong>程序……</p><p><img src="d7992bd/install_mono_why.png" alt="不管怎么说，还是要感谢TI"></p><p>装好mono，就可以了跑了。</p><hr><h2 id="UniFlash"><a href="#UniFlash" class="headerlink" title="UniFlash"></a>UniFlash</h2><p>UniFlash的安装和使用倒没有什么坑，GUI弹窗安装，GUI使用（也有cli模式）。</p><p>不知道为什么，之前在Debian里用总是需要root权限才能正常识别，在Ubuntu里面倒是没有任何问题。。。</p><hr><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>其实仅仅安装sdk就可以进行开发，ccs只是IDE。</p><p>先来看看纯正unix风格的方式。</p><p>在SDK的安装目录下，有一个子目录/packages/scripts/unix, 包含一个setenv.sh，source它就可以导入SDK固件需要的各种环境变量。默认使用的器件是xwr68xx， 如果用别的器件需要修改这个文件。</p><p><img src="d7992bd/install_sdk_env.png" alt="导入环境变量"></p><p>TI只提供了bash的版本，zsh直接导入会报错（不过其实也无关紧要，一样跑）</p><p>接着进到SDK自带的demo目录。</p><p><img src="d7992bd/install_make_demo.png" alt="进入demo目录"></p><p>dss目录是 DSP核的代码<br>mss目录是 Cortex R核的代码</p><p>看到makefile了嘛！</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j8 all</span><br></pre></td></tr></tbody></table></figure><p>就能得到可以下载的bin文件。</p><hr><p>如果是GUI环境下的配置， 则要复杂一下。</p><p>在安装完sdk后第一次打开ccs10, 会提示找到新的组建。</p><p>在 [Resource Explorer] -&gt; [mmWave Sensors] -&gt; [Industrial Tollbox] -&gt; [Labs] 选择合适的例程，并导入到eclipse环境。</p><p><img src="d7992bd/install_gui_build.png" alt="GUI导入"></p><p>如果使用的是DSP版本， 则需要分别导入DSS项目和MSS项目。</p><p>首先编译DSS部分， 应该没有问题问题，<br>然后编译MSS部分， 如果正确配置，一开始也没有问题，但是在最后会出现一堆乱七八糟的问题。</p><p>经过一番折腾，发现这是CSS导入时的bug，没有针对linux环境做足够的测试。</p><p>好在修改不难，在项目上右键，选择属性，弹框左侧选择Build, 右边找到Steps， 修改一些细节。。<br><img src="d7992bd/ccs10_image_creator.png" alt="导入程序的bug"></p><p>最后，重新编译，就能得到可以下载的二进制程序。</p><hr><p>to be continued..</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;在LinuX环境下配置TI毫米波雷达开发环境&quot;&gt;&lt;a href=&quot;#在LinuX环境下配置TI毫米波雷达开发环境&quot; class=&quot;headerlink&quot; title=&quot;在LinuX环境下配置TI毫米波雷达开发环境&quot;&gt;&lt;/a&gt;在LinuX环境下配置TI毫米波雷达开发
      
    
    </summary>
    
    
      <category term="毫米波雷达" scheme="http://blog.tensor-robotics.com/categories/%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="雷达" scheme="http://blog.tensor-robotics.com/tags/%E9%9B%B7%E8%BE%BE/"/>
    
      <category term="毫米波" scheme="http://blog.tensor-robotics.com/tags/%E6%AF%AB%E7%B1%B3%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>闭门造车日记 第五篇</title>
    <link href="http://blog.tensor-robotics.com/archives/52155a9e.html"/>
    <id>http://blog.tensor-robotics.com/archives/52155a9e.html</id>
    <published>2020-06-14T06:20:39.000Z</published>
    <updated>2020-06-14T10:22:13.746Z</updated>
    
    <content type="html"><![CDATA[<h1 id="造车日记-milestone-1"><a href="#造车日记-milestone-1" class="headerlink" title="造车日记 milestone 1"></a>造车日记 milestone 1</h1><h2 id="第一阶段达成"><a href="#第一阶段达成" class="headerlink" title="第一阶段达成"></a>第一阶段达成</h2><ul><li>基础机械完工</li><li>基础电子完工</li><li>基础软件完工</li></ul><p>达到使用遥控器控制的目标。</p><hr><h2 id="开源"><a href="#开源" class="headerlink" title="开源"></a>开源</h2><p><a href="https://github.com/chopin1998/vechicle_pcb" target="_blank" rel="noopener">驱动板电路</a></p><p><a href="https://github.com/chopin1998/vehcile_firmware" target="_blank" rel="noopener">固件和测试软件</a></p><hr><h2 id="关于PCB"><a href="#关于PCB" class="headerlink" title="关于PCB"></a>关于PCB</h2><p>目前github中的版本与实际稍微有些差异：</p><ul><li>去掉了<strong>SWD</strong>接口，并增加了Boot和nRST按键，以方便使用内建的USB Bootloader</li><li>增加了 D15，可以在没有外部供电情况下使用USB供电，方便调试</li></ul><p>不足和今后可能改进</p><ul><li>F303系列没有内建USB上拉电阻，需要外部上拉，目前是飞线。如果有机会改进会增加上拉电阻相关电路或者更换高等级器件</li><li>电池接插件公母对调一下似乎更加合理</li></ul><hr><h2 id="一些好玩儿的点"><a href="#一些好玩儿的点" class="headerlink" title="一些好玩儿的点"></a>一些好玩儿的点</h2><ul><li>总电流监控</li></ul><p>在电池输出端有一颗0.01欧姆电阻，配合<strong>INA138</strong>进行高位电流采样，然后通过STM32F3内部的<strong>OPA</strong>继续放大后获取总电流信息</p><ul><li>充电电路</li></ul><p>使用<strong>LM5050</strong>和一颗mosfet，配置成理想二极管。这样即使充电触点被恶意短接，也不会有任何意外。</p><p>至于未来充电是触点，还是无线……让我看看口袋里还剩多少钱……</p><ul><li>WS2813 驱动电路</li></ul><p>WS2813的IO无法兼容3.3v操作电平，因此在其供电端串联二极管，以降低其Vcc。</p><p>此外WS2813的数据口接在STM32的<strong>SPI</strong> TX管脚，并在软件中启动<strong>DMA</strong>传输数据，不额外占用cpu时间。</p><p>在软件中同时维护了GRB显存和BIN原始码流。缺点是费点儿内存，但是架不住RAM大呀，小车上最多就100来个嘛，毫无压力。</p><ul><li>关于CubeMX</li></ul><p>其实在早些年我是鄙视CubeMX的，总觉得这样不够hardcore，不过如今依然逃不过真香定律。。。</p><p>站在高处设计的感觉还是棒棒的，而且需要直接操作寄存器时，也有办法。</p><p>整套stm32的开发体验在Linux环境下还算令人满意。</p><ul><li>PID 速度控制</li></ul><p>本来PID并不复杂也手写过几次，不过看到ARM <strong>CMSIS</strong>里有DSP版本的PID就索性试了试。</p><p>教科书般经典的实现，似乎比我写的要好用？！关键是代码因此看起来非常简单。</p><p>需要注意的是，Cortex M4核心的DSP毕竟比较简单，完整的32bit浮点是不支持的，我现在代码里用的f32类型其实并没有真的调用到DSP指令，最多是有硬件乘法器、除法器加成.</p><p>要使用真的DSP加速（MAC），只能使用q15这种数据类型。使用这个数据类型需要一波归一化操作。我也是后来才学到，所以github中的代码还没有更新。</p><ul><li>stm32死机事件</li></ul><p>之前的调试都在我的笔记本上完成，最后上机时，第一次将控制板和小车主控电脑（目前是rk3399）用usb连接起来的时候，stm32居然死机了……</p><p>最终我在自行车上想到了解决方法，在主控电脑上删除了 modem manager的包……</p><p>原因是stm32的usb cdc实现在linux看来是一个ACM设备，不过并没有实现modem类的其它调用，如果存在modem manger， linux系统会发起设备类查询，就把stm32被逼死了……所以如果只是用串口的话，最偷懒的方法就是删掉这个包。。。</p><ul><li>手柄功能</li></ul><p>左手摇杆控制前、后、左、右方向，右手油门如果完全松开是蠕动模式。<br>右手摇杆目前是旋转功能。</p><p>其它按键暂时还没有用上，以后可能也不会用上了。</p><hr><h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><h3 id="决定最终的车载电脑"><a href="#决定最终的车载电脑" class="headerlink" title="决定最终的车载电脑"></a>决定最终的车载电脑</h3><p>目前的候选依旧是</p><ul><li>RK3399</li><li>nVidia Jetson Nano</li></ul><p>RK3399的CPU要快过 jetson， 毕竟第二代双大核心加四个小核心 pk 第一代四个大核心。毛估估大部分的直线计算可能要快15%以上，有些则要更快。</p><p>用jetson的理由无外就是cuda啦，虽然只是从tx1腰斩而来的阉割版本，全速计算还是有可观的算力。</p><p>另外一个考量点，是各自对双目的支持水平，到时候可能要做一个简单的对比。</p><h3 id="测试基于movidius双目模块"><a href="#测试基于movidius双目模块" class="headerlink" title="测试基于movidius双目模块"></a>测试基于movidius双目模块</h3><p>嗯</p><h3 id="测试基于毫米波雷达的定位方式"><a href="#测试基于毫米波雷达的定位方式" class="headerlink" title="测试基于毫米波雷达的定位方式"></a>测试基于毫米波雷达的定位方式</h3><p>啊</p><hr><p>to be continued..</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;造车日记-milestone-1&quot;&gt;&lt;a href=&quot;#造车日记-milestone-1&quot; class=&quot;headerlink&quot; title=&quot;造车日记 milestone 1&quot;&gt;&lt;/a&gt;造车日记 milestone 1&lt;/h1&gt;&lt;h2 id=&quot;第一阶段达成&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="造车日记" scheme="http://blog.tensor-robotics.com/categories/%E9%80%A0%E8%BD%A6%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="小车" scheme="http://blog.tensor-robotics.com/tags/%E5%B0%8F%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>毫米波雷达 第四篇</title>
    <link href="http://blog.tensor-robotics.com/archives/62e757fa.html"/>
    <id>http://blog.tensor-robotics.com/archives/62e757fa.html</id>
    <published>2020-05-28T13:45:15.000Z</published>
    <updated>2020-06-16T08:04:39.747Z</updated>
    
    <content type="html"><![CDATA[<h1 id="毫米波雷达的选型"><a href="#毫米波雷达的选型" class="headerlink" title="毫米波雷达的选型"></a>毫米波雷达的选型</h1><h2 id="器件"><a href="#器件" class="headerlink" title="器件"></a>器件</h2><p>经过一段时间的摸索，目前确定还是用国际大厂TI的芯片先练练手。</p><p>选择器件为 <a href="http://www.ti.com/product/IWR6843" target="_blank" rel="noopener"><strong>IWR6843</strong></a></p><p>如<a href="/archives/a8c20115.html" title="前文">前文</a>所述，这是一颗集成式毫米波雷达SoC，主要技术特点：</p><ul><li>60 - 64Ghz 连续调制，4GHz带宽</li><li>3TX</li><li>4RX</li><li>Cortex R4F</li><li>集成FFT、滤波、CFAR等硬件加速</li><li>集成C674x DSP</li></ul><p>本来想要一颗77G的芯片，因为标称频率范围是76 - 81GHz， 也就是5GHz带宽，不过看详细的文档，似乎有一部分带宽的无线电是被分配给了汽车，所以77G的芯片是两部分带宽，一个1GHz，一个也是4GHz。</p><p>当然更重要的一个原因是，目前IWR6843还有一个<strong>AoP</strong>版本，也就是芯片上直接封装了天线！这对日后自己做产品来说非常有利。几十G的射频电路，别说画了，找个代工厂估计都要费些力气。</p><p>所以这次就先选了<strong>IWR6843</strong>的开发板。</p><hr><h2 id="功能框图"><a href="#功能框图" class="headerlink" title="功能框图"></a>功能框图</h2><p><img src="62e757fa/block.png" alt="45nm RFCMOS 制程"></p><h3 id="RF和模拟模块"><a href="#RF和模拟模块" class="headerlink" title="RF和模拟模块"></a>RF和模拟模块</h3><h4 id="时钟域"><a href="#时钟域" class="headerlink" title="时钟域"></a>时钟域</h4><p><img src="62e757fa/clock.png" alt="时钟的产生"></p><p>系统使用一个外部40MHz晶振产生内部所需的各种时钟。</p><h4 id="发射电路"><a href="#发射电路" class="headerlink" title="发射电路"></a>发射电路</h4><p><img src="62e757fa/tx.png" alt="一个通道"></p><p>IWR6843有三个独立的发射通道。不过同一时间只能同时使用其中的两个。</p><p>当使用分时三天线策略时，可以实现3D测定。</p><p>设备支持6bit的线性相移以支持MIMO雷达和发射波束成形等应用。</p><h4 id="接收电路"><a href="#接收电路" class="headerlink" title="接收电路"></a>接收电路</h4><p><img src="62e757fa/rx.png" alt="一个通道"></p><p>IWR6843有四个独立的接收通道，并且可以同时使用。<br>器件为快速啁啾信号优化，带通的中频信号链支持可配置的滤波，从175KHz至最大10MHz。</p><h4 id="雷达子系统处理器"><a href="#雷达子系统处理器" class="headerlink" title="雷达子系统处理器"></a>雷达子系统处理器</h4><p>此处理器有其独立的ROM/RAM， 用于执行内置的射频校准程序、底层操作。<br>用户并不能直接操作这个控制器，TI提供了封装好的固件，使用基于mailbox的API，通过消息机制和整个雷达子系统通讯。</p><p><img src="62e757fa/prog_model.png" alt="编程模型"></p><h3 id="处理器系统"><a href="#处理器系统" class="headerlink" title="处理器系统"></a>处理器系统</h3><p><img src="62e757fa/processor.png" alt="简化的处理器系统"></p><p>主要来看有两个可编程的大核心：</p><ul><li>一个<strong>Cortex R4F</strong> 作为主控<ul><li>200 MHz 时钟频率</li><li>注意这是Ｒ，不是Ｍ也不是Ａ。</li></ul></li><li>一个<strong>C674x DSP</strong> 作为协信号处理器<ul><li>600 MHz 时钟频率</li></ul></li></ul><p>LVDS将ADC高速同步泵出，可以作为log或者为外部其它处理器提供原始数据。</p><p>HIL则是高速信号输入接口。</p><p>其中的HWA为雷达硬件加速器，包含了一些FMCW常用的处理硬核，可以降低主处理器负担。</p><hr><h2 id="供电"><a href="#供电" class="headerlink" title="供电"></a>供电</h2><p>芯片需要<strong>4</strong>个电源轨:</p><ul><li><p>VDD 数字核心、SRAM</p><ul><li>1.2v</li></ul></li><li><p>数字IO</p><ul><li>3.3v 或 1.8v</li></ul></li><li><p>射频电源</p><ul><li>1.3v 或 1.0v(旁路内部LDO)</li></ul></li><li><p>模拟电源</p><ul><li>1.8v</li></ul></li></ul><p>其中射频电源和模拟电源如果直接使用开关电源供电，需要额外的LC滤波。</p><p>同时芯片有两个电源域，一个是主电源，一个是DSP电源。DSP电源可以动态开关。</p><p>可以使用多路的PMIC电源芯片来管理，例如：</p><ul><li>LP87702系列</li><li>LP87524系列</li></ul><p>都是给IWR/AWR系列专门设计的PMIC。</p><p>整个系统的功耗相对来说还是不低的， 5v总电源轨的话，至少需要2~3A的充沛电流。</p><p>芯片本身的热量也相当可观。<br><img src="62e757fa/curret_ratings.png" alt="各电源轨最大电路"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;毫米波雷达的选型&quot;&gt;&lt;a href=&quot;#毫米波雷达的选型&quot; class=&quot;headerlink&quot; title=&quot;毫米波雷达的选型&quot;&gt;&lt;/a&gt;毫米波雷达的选型&lt;/h1&gt;&lt;h2 id=&quot;器件&quot;&gt;&lt;a href=&quot;#器件&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
      <category term="毫米波雷达" scheme="http://blog.tensor-robotics.com/categories/%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="雷达" scheme="http://blog.tensor-robotics.com/tags/%E9%9B%B7%E8%BE%BE/"/>
    
      <category term="毫米波" scheme="http://blog.tensor-robotics.com/tags/%E6%AF%AB%E7%B1%B3%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>毫米波雷达 第三篇</title>
    <link href="http://blog.tensor-robotics.com/archives/d5ca4e9f.html"/>
    <id>http://blog.tensor-robotics.com/archives/d5ca4e9f.html</id>
    <published>2020-05-21T12:28:37.000Z</published>
    <updated>2020-05-21T13:16:55.619Z</updated>
    
    <content type="html"><![CDATA[<h1 id="毫米波雷达的基本工作原理-续"><a href="#毫米波雷达的基本工作原理-续" class="headerlink" title="毫米波雷达的基本工作原理 续"></a>毫米波雷达的基本工作原理 续</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="/archives/98d4edcd.html" title="毫米波雷达第二篇">毫米波雷达第二篇</a>进一步介绍了毫米波雷达的内部构成，和基本测距原理。</p><p>本番将介绍毫米波雷达测速功能和方位角测定功能的基本原理。</p><hr><h2 id="速度测量"><a href="#速度测量" class="headerlink" title="速度测量"></a>速度测量</h2><h3 id="单一目标测速"><a href="#单一目标测速" class="headerlink" title="单一目标测速"></a>单一目标测速</h3><p>在<a href="/archives/a8c20115.html" title="毫米波雷达第一篇">毫米波雷达第一篇</a>中，提到雷达具有对目标测速的能力加成，以及对目标微小移动的检测能力。</p><p>在FMCW雷达技术中，可以通过发射两次间隔为$T_c$的啁啾信号来获取速度信息。</p><p>对于两次反射来的信号，通过上一回说的FFT技术来提取其“调性”（<strong>中频频峰</strong>和<strong>相位差</strong>）。</p><p>因为两次啁啾的时间间隔非常短，就算物体移动很快，在这段微小时间内的位移也不会很大，所以对应的中频频率差别可能小到无法分别。</p><p>不过此时它们的相位差将会出现巨大变化，哪怕目标运动速度很低，由此可以计算出速度。</p><p>在上一篇中，已经知道相位差：<br>$\phi = \frac{4\pi d}{\lambda}$</p><p>取其微分形式：<br>$\Delta \phi = \frac{4\pi v T_c}{\lambda}$</p><p>这里，假定两次啁啾期间物体运动了1mm（使用5mm波长）， 那么相位差将有144°的巨大差异！</p><p>将$v$放在等式最左边，得到：<br>$v = \frac{\lambda \Delta \phi}{4 \pi T_c }$</p><p>由此求得目标速度。</p><p>然而，由于速度信息隐藏在相位中，就会带来一个问题：<strong>ambiguity（模糊性）</strong>， 在<a href="/archives/78201d81.html" title="关于ToF 番二">关于ToF 番二</a> 中其实也有类似的问题。</p><p>只有当$\left| \Delta \phi\right| &lt; \pi$的时候，测得量才有正确的意义。</p><p>也就是说，速度$v$需要小于$\frac{\lambda}{4 T_c}$</p><p>用公式表达雷达能接受的最快运动速度：<br>$v_{max} = \frac{\lambda}{4 T_c}$</p><p>不过需要说明的是，这里求出目标速度，应该说是目标相对雷达平面移动的速度分量，是径向速度。</p><hr><h3 id="多目标测速"><a href="#多目标测速" class="headerlink" title="多目标测速"></a>多目标测速</h3><p>然而，这种方式无法应对相对雷达等距的两个以上目标的测速。因为若两个目标相对雷达距离相同，其各自回波延时也相同，因此中频信号中的相位信息会混叠在一起。</p><p>为此，人们想出其它的办法：</p><p>雷达发射更多的Chirp。</p><p>一组<strong>N</strong>个等时间隔的Chrips序列，被称为一个<strong>啁啾帧</strong>。</p><p>假如有两个与雷达等距的目标A、B，它们的速度分别为$v_a$、$v_b$。</p><p>可以想象，中频信号在经过FFT后，会得到<strong>N</strong>个几乎在同一位置的波峰，但是每个峰都会有一个不同的相位信息。</p><p>而每个相位信息都是A、B的相位角的融合。所以需要做的就是将N个相位角，恢复成两个相位角……</p><p>说起来有点儿绕，看图吧<br><img src="d5ca4e9f/multi_object_v.jpg" alt="从一组向量中恢复出两个独立的向量"></p><p>怎么做呢？这时数学家又跑出来了，他们说：</p><p>把那组<strong>和</strong>的向量塞进我的黑箱子，我的黑箱子就能还给你两个<strong>加数</strong>。<br>我的黑箱子叫：“<strong>Doppler FFT</strong>” <strong>多普勒-傅里叶变换</strong></p><p>这波Doppler FFT操作之后，又会得到两个峰，分别是$\omega_A$和$\omega_B$。</p><p>由此得到两个物体分别的速度：<br>$\begin{cases}<br>    v_A = \frac{\lambda \omega_A}{4\pi T_c}\\<br>    v_B = \frac{\lambda \omega_B}{4\pi T_c}<br>\end{cases}$</p><p>Oh my lady gaga……</p><p>如果世间没有数学家，人类就得倒退回每天收集果子的时代，那该多美好呀……</p><hr><h3 id="测速分辨率"><a href="#测速分辨率" class="headerlink" title="测速分辨率"></a>测速分辨率</h3><p>根据离散傅里叶变换理论可知，当两个离散频率$\omega_1$和$\omega_2$的差，大于$\frac{2\pi}{N}$ 时，就可以被分辨。</p><p>而$\Delta \omega = \frac{4\pi v T_c}{\lambda}$</p><p>又有 $v_{res} T_f = N T_c$</p><p>可以得到速度分辨率$v_{rev} = \frac{\lambda}{2T_f}$</p><p>既$\rightarrow$ 雷达速度分辨率与帧时间$T_f$成反比， 帧时间越短，速度分辨率越高。</p><hr><h2 id="方位角测定"><a href="#方位角测定" class="headerlink" title="方位角测定"></a>方位角测定</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>FMCW雷达可以在其水平面估计反射波角度。这是一种被称为 <strong>到达角(AoA)</strong> 检测的技<br>术。</p><p><img src="d5ca4e9f/aoa.png" alt="AoA"></p><p>让我想到<strong>UWB定位</strong>和最新的<strong>蓝牙定位</strong>技术，也用到了类似的技术。</p><p>要使用AoA，需要用到RX天线阵列。目标的反射回波，到达不同的RX天线时，会有一个空间上的距离差异，在中频信号经过FFT或者Doppler-FFT的时候，会看到不同。而这个不同包含了角度的信息。</p><p>以最简化的例子<br><img src="d5ca4e9f/aoa_cal.png" alt="双天线的角度估计"></p><p>同一个目标回波到达两个RX天线的相位差：<br>$\Delta \Phi = \frac{2\pi \Delta d}{\lambda}$</p><p>根据几何， $\Delta d = l \sin(\theta)$，其中$l\rightarrow$天线间距。</p><p>因此得到到达角：<br>$\theta = sin^{-1}(\frac{\lambda \Delta \phi}{2\pi l})$</p><p>带入后会得到 $\theta = \sin(\theta)$的奇怪结果。这被称为非线性近似。</p><p>只有当$\theta$较小时，才会更加准确。</p><hr><h3 id="雷达视场-FoV"><a href="#雷达视场-FoV" class="headerlink" title="雷达视场 FoV"></a>雷达视场 FoV</h3><p>因为AoA使用相位测定， 所以依旧绕不开 $\left| \Delta \phi \right| &lt; 180^\circ$ 的非模糊性问题。</p><p>由上面的公式，得到：<br>$\theta_{max} = \pm sin^{-1}(\frac{\lambda}{2l})$</p><p>例如， 如果天线之间间隔$l = \frac{\lambda}{2}$， 那么最大视场角度就是$\pm 90^\circ$</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过三篇blog完整描述了毫米波雷达的特点、基本工作原理。</p><p>是一头雾水呢，还是一头雾水？</p><p>在后续的文章中，将进行实际的毫米波雷达开发和评估。</p><p><img src="d5ca4e9f/antenna.jpg" alt="真实的毫米波雷达天线"></p><p>敬请期待<br>to be continued…</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;毫米波雷达的基本工作原理-续&quot;&gt;&lt;a href=&quot;#毫米波雷达的基本工作原理-续&quot; class=&quot;headerlink&quot; title=&quot;毫米波雷达的基本工作原理 续&quot;&gt;&lt;/a&gt;毫米波雷达的基本工作原理 续&lt;/h1&gt;&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot;
      
    
    </summary>
    
    
      <category term="毫米波雷达" scheme="http://blog.tensor-robotics.com/categories/%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="雷达" scheme="http://blog.tensor-robotics.com/tags/%E9%9B%B7%E8%BE%BE/"/>
    
      <category term="毫米波" scheme="http://blog.tensor-robotics.com/tags/%E6%AF%AB%E7%B1%B3%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>毫米波雷达 第二篇</title>
    <link href="http://blog.tensor-robotics.com/archives/98d4edcd.html"/>
    <id>http://blog.tensor-robotics.com/archives/98d4edcd.html</id>
    <published>2020-05-19T13:37:42.000Z</published>
    <updated>2020-05-21T05:54:41.633Z</updated>
    
    <content type="html"><![CDATA[<h1 id="毫米波雷达的基本工作原理"><a href="#毫米波雷达的基本工作原理" class="headerlink" title="毫米波雷达的基本工作原理"></a>毫米波雷达的基本工作原理</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="/archives/a8c20115.html" title="上一篇">上一篇</a>中介绍了雷达的基本概念</p><ul><li>雷达系统<strong>发射</strong>电磁波信号</li><li>路径中的物体<strong>反射该</strong>电磁波</li><li>雷达系统<strong>处理和分析</strong>反射波，计算出目标的距离、速度和方位角等信息</li></ul><p>本番将从更进一步展开毫米波雷达的工作细节。</p><p>再次声明，本人业余电子工程师，雷达更是首次接触，如有理解不当，还请多多指教。</p><p>下面进入正文。</p><p>不同的雷达使用不同的波段， 波长在1mm 至 100m的广阔频段都可以用于雷达。</p><p>既然被称为<strong>毫米波</strong>雷达，那主要波段就是1mm~10mm之间， 对应于300GHz ~ 30GHz<br><img src="98d4edcd/wavelen2freq.png" alt=" $f = \frac c\lambda$ "></p><p>不过目前因为法规和技术的原因，典型的毫米波雷达频段主要有：</p><ul><li>24GHz  ~12mm</li><li>60GHz  ~5mm</li><li>77GHz ~4mm (其中77.5—78.0GHz为汽车雷达专用的无线电频段)</li></ul><p>下文中，以60GHz/ 77GHz 的雷达为例。</p><hr><h2 id="系统框图"><a href="#系统框图" class="headerlink" title="系统框图"></a>系统框图</h2><p>正如前文所述的雷达基本系统构成<br><img src="98d4edcd/block.png" alt="系统框图"></p><ol><li><a href="https://en.wikipedia.org/wiki/Synthesizer" target="_blank" rel="noopener">synth</a> <strong>合成器</strong>，产生调制信号</li><li>TX ant, <strong>发射天线</strong>将无线电波送出系统</li><li>RX ant, <strong>接收天线</strong>将拾取被目标反射的电波</li><li><a href="https://en.wikipedia.org/wiki/Frequency_mixer" target="_blank" rel="noopener">mixer</a>, <strong>混频器</strong>将接收到的信号和发射信号作为输入，并产生一个中间结果，供后级进一步处理</li></ol><hr><h3 id="合成器"><a href="#合成器" class="headerlink" title="合成器"></a>合成器</h3><p>雷达的发射信号是经过调制的，调制的手段有很多，这里只说明FMCW（调频连续波）方式。在一个FMCW周期中，是一个频率会随时间线性增加的正弦波信号，一个这样的周期也叫一个<strong>啁啾（Chirp）</strong></p><p>我plot了一个可能不太标准的Chirp<br><img src="98d4edcd/chirp.png" alt="啁啾 Twitter"></p><p>上图的坐标系是 <strong>振幅-时间</strong>，<br>对于同一个啁啾信号，如果改用 <strong>频率-时间</strong> 坐标系的话，会像下面这个样子</p><p><img src="98d4edcd/chirp_ft.png" alt="频率-时间坐标表达"></p><p>在这幅图中，</p><ul><li>啁啾的<strong>起始频率</strong> $f_c = 77GHz$</li><li>结束频率$81GHz$， 因此<strong>带宽</strong>$B = 4GHz$</li><li><strong>周期</strong>$Tc = 40us$， 因此<strong>斜率</strong>$S = 100MHz/us$</li></ul><p>合成器的工作就是周而复始的产生这种Chrip信号。</p><hr><h3 id="混频器"><a href="#混频器" class="headerlink" title="混频器"></a>混频器</h3><p>混频率是一种非线性电路，它接受两路输入信号，并产生出一路新的信号。</p><p>而内部的处理则会根据不同的应用而异。</p><hr><h2 id="测距"><a href="#测距" class="headerlink" title="测距"></a>测距</h2><h3 id="测距原理"><a href="#测距原理" class="headerlink" title="测距原理"></a>测距原理</h3><p>假设$t$时刻的<strong>TX信号</strong>为（如前文，调制信号为随时间变化的正弦波）：</p><p>$y_{tx} = sin(\omega_{tx} t + \phi_{tx})$</p><p>而<strong>RX信号</strong>呢，电波从天线发射，到被目标反射折回，需要一定的时间，因此RX信号，只是被“延时”了TX波形（怀念开发<a href="https://blog.tensor-robotics.com/categories/ToF/">TOF</a>的日子…）：</p><p>$y_{rx} = sin(\omega_{rx} t) + \phi_{rx})$</p><p>雷达中的混频器的工作就是得到一个新函数：</p><p>$y_{if} = sin[(\omega_{tx}-\omega_{rx})t + (\phi_{tx} - \phi_{rx})]$</p><p>这个输出也被称为<strong>中频</strong>(intermediate frequency)。</p><p>聪明如我的你应该要发出<strong>wow</strong>的声音了吧？</p><p>这个中频实际包含了RX和TX信号的<strong>频差</strong>和<strong>相位差</strong>！</p><hr><p>如果还没懂的话，那就看图说话吧。</p><p><img src="98d4edcd/if_signal_info.png" alt="中频信号包含的信息"></p><p>根据初等物理($时间=\frac{路程}{速度}$）我们知道TX/RX两个信号的延时等于</p><p>$\tau = \frac{2*d}{c}$</p><ul><li>$d$ 是目标和雷达之间的距离</li><li>$c$ 是电磁波的速度，也就是光速</li></ul><p>需要注意的是，中频信号仅在TX和RX的重叠期有效（因为中频信号由混频器产生）。</p><p>而中频信号的起始相位$\boldsymbol{\phi_0}$，就是TX和RX信号在该时刻的相位差。</p><p>同时根据上图，也可以得到：<br>$\phi_0 = 2\pi f_c \tau$ ($f_c \rightarrow $TX啁啾的起始频率)</p><p>将$\tau$带入上式，又可以得到：<br>$\phi = \frac{4\pi d}{\lambda}$</p><p>不过这只是一个近似，因为频率在变化，更精确的表述应该是：<br>$\Delta\phi = 4\pi \Delta\frac{d}{\lambda}$</p><hr><p>总结一下，当<strong>一个</strong> <strong>静态</strong>目标出现在在雷达区间内时，IF信号会是一个正弦波：</p><p>$IF\rightarrow Asin(2\pi f_0 + \phi_0)$</p><ul><li>$f_0 = \frac{S2d}{c}$</li><li>$\phi_0 = \frac{4\pi d}{\lambda}$</li></ul><p>前面强调静态的原因是，如果目标相对雷达有运动，那么会有<a href="https://en.wikipedia.org/wiki/Doppler_effect" target="_blank" rel="noopener">多普勒效应</a>。不过在快速FMCW系统中，这个效应非常轻微，并且会在后续的信号处理中被修正。</p><hr><h3 id="多目标测距"><a href="#多目标测距" class="headerlink" title="多目标测距"></a>多目标测距</h3><p>那么如果有多个目标出现在不同的区域呢？</p><p>雷达会收到多个啁啾回波。</p><p>而每个回波， 回因为远近距离不同，而有不同程度的“延时”。</p><p><img src="98d4edcd/multi_object_if.jpg" alt="原谅我不羁的画风"></p><p>更远的目标意味着更大的回波延时，也就意味着更大的频差。</p><p>那么如何从一个混叠了多个波的信号中，还原出每个信号的调性呢？</p><p><a href="https://en.wikipedia.org/wiki/Fourier_transform" target="_blank" rel="noopener"><strong>傅里叶变换</strong></a>！！</p><p><del>数学家，是一群脑子有病的人。我的脑子也有病，可我数学很渣。。。可见得的不是一种病</del></p><hr><h3 id="测距分辨率"><a href="#测距分辨率" class="headerlink" title="测距分辨率"></a>测距分辨率</h3><p>对于电波雷达来说，<strong>距离分辨率</strong>是衡量其性能的主要指标。当两个物体过于接近时，雷达无法将它们分开。按照上文的分析，这是因为中频区域内有两个过于靠近的横线。</p><p>根据傅里叶变换，如果想增加距离分辨率，需要增加中频信号的长度（横着的长度），也就是增加<strong>带宽</strong>。</p><p>同时，观测窗口$T$可以分辨间隔$\frac{1}{THz}$ (1ps)的频率分量。这意味着，只要偏差满足下列关系，就可以被分辨：</p><p>$\Delta f &gt; \frac{1}{T_c}$</p><p>其中$T_c$是观测时间长度。</p><p>而频差 $\Delta f = \frac{S2\Delta d}{c}$， 所以上面的式子整理得到：</p><p>$\Delta d &gt; \frac{c}{2ST_c} = \frac{c}{2B}$</p><p>通过一顿操作，发现原来距离分辨率仅仅取决于啁啾的<strong>带宽</strong>！</p><p>道理都懂，但是结论怎么如此神奇了？！</p><p>对于<strong>5GHz</strong>啁啾带宽的雷达，距离分辨率就是 大约29.979mm。</p><hr><h2 id="下回预告"><a href="#下回预告" class="headerlink" title="下回预告"></a>下回预告</h2><p>在<strong>毫米波雷达</strong>的后续文章中， 将进一步介绍<strong>测速</strong>、<strong>方位测定</strong>等原理</p><p>to be continued…</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;毫米波雷达的基本工作原理&quot;&gt;&lt;a href=&quot;#毫米波雷达的基本工作原理&quot; class=&quot;headerlink&quot; title=&quot;毫米波雷达的基本工作原理&quot;&gt;&lt;/a&gt;毫米波雷达的基本工作原理&lt;/h1&gt;&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;
      
    
    </summary>
    
    
      <category term="毫米波雷达" scheme="http://blog.tensor-robotics.com/categories/%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="雷达" scheme="http://blog.tensor-robotics.com/tags/%E9%9B%B7%E8%BE%BE/"/>
    
      <category term="毫米波" scheme="http://blog.tensor-robotics.com/tags/%E6%AF%AB%E7%B1%B3%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>毫米波雷达 第一篇</title>
    <link href="http://blog.tensor-robotics.com/archives/a8c20115.html"/>
    <id>http://blog.tensor-robotics.com/archives/a8c20115.html</id>
    <published>2020-05-14T12:43:25.000Z</published>
    <updated>2020-05-20T02:42:42.391Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于毫米波雷达"><a href="#关于毫米波雷达" class="headerlink" title="关于毫米波雷达"></a>关于毫米波雷达</h1><h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><h3 id="幼时"><a href="#幼时" class="headerlink" title="幼时"></a>幼时</h3><p>是在小学的时候，第一次听到“<strong>雷达</strong>”这个词。大概是在一副关于武器的扑克牌上。</p><p>感觉酷酷的。</p><p>然而一直到最近， 我才知道“雷达”这个音译的来源——<a href="https://en.wikipedia.org/wiki/Radar" target="_blank" rel="noopener"><strong>RADAR</strong></a>，原来是一个递归缩写</p><ul><li>最早的定义来自1940年鹰酱海军的造字 <strong>RA</strong>dio <strong>D</strong>etection <strong>A</strong>nd <strong>R</strong>anging</li><li>而后又有了一个似乎更贴切的定义 <strong>R</strong>adio <strong>A</strong>zimuth <strong>D</strong>irection <strong>A</strong>nd <strong>R</strong>anging</li></ul><p>细品之下，<strong>雷</strong>和<strong>达</strong>这俩字太传神了，简直不像是音译。</p><p>再大一点儿，学校有无线电小组，当时觉得拿着别人做的东西，听着滴滴响，到底找东西有啥意思？还不如坐在电脑前操着<a href="https://zh.wikipedia.org/wiki/Logo_(%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80)" target="_blank" rel="noopener">小龟头</a>画出各种奇怪的图形比较对我胃口。</p><p>就这样因为年少无知，错过了入门版的雷达，大概也错过了科班EE的经历。</p><h3 id="大学毕业"><a href="#大学毕业" class="headerlink" title="大学毕业"></a>大学毕业</h3><p>做毕业设计的时候，认识了一个朋友，后来他去了国内某研究所，听说和雷达有点儿关系。</p><h3 id="老婆"><a href="#老婆" class="headerlink" title="老婆"></a>老婆</h3><p>领导曾经在一家船舶雷达公司工作。</p><h3 id="如今"><a href="#如今" class="headerlink" title="如今"></a>如今</h3><p>真没想到，如今的我居然会再次接触雷达，像个孩子一样。</p><hr><h2 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>雷达，首先向空间<strong>发射</strong>电磁波，在测量距离内的物体会<strong>反射</strong>电磁波，雷达<strong>监听并处理</strong>信号，得到物体的位置信息。</p><p>等等！<br>这不是和<strong>ToF</strong>很像？！</p><ul><li><a href="/archives/43a03328.html" title="关于ToF 番一">关于ToF 番一</a></li><li><a href="/archives/78201d81.html" title="关于ToF 番二">关于ToF 番二</a></li><li><a href="/archives/3a7c8b8c.html" title="关于ToF 番三">关于ToF 番三</a></li><li><a href="/archives/76aee792.html" title="关于ToF 番四">关于ToF 番四</a></li></ul><p>一想也是， 大家原来都是电磁波。</p><p><img src="a8c20115/spectrum.jpg" alt="只是红外光波的频率更高，波长更短"></p><p>地球人实际运用雷达始于二战。</p><p>因为战争，港口变得异常繁忙，北大西洋的军港经常处于浓雾之中不时有船舶碰撞。</p><p>为了解决这个问题，同时也帮助船舶能在夜间作业，英、德两国秘密研发雷达。</p><p>英国选择了<strong>3MHz-30MHz</strong>的频率，因为当时电子技术还十分有限，这是日不落帝国的频率上限。较低的频率导致天线异常庞大，较长的波长也导致分辨率不佳。 但已经能作为岸基固定雷达站，超视距侦测敌方目标。</p><p>而当时的德国掌握了大量黑科技，一上来就是短波雷达，频率在<strong>十个Ghz到40GHz</strong>。并且功率更大。因为频率高，所以天线可以比较小，后来被安装在飞机上。然而德国人的雷达频率过于接近水蒸气的谐振波长，在大气中存在衰减，距离较短，并且容易受到雨雪影响。</p><p>之后的雷达技术，日新月异，已经不是我这种门外汉能痴心妄想的了…</p><hr><h3 id="那么为什么不用ToF"><a href="#那么为什么不用ToF" class="headerlink" title="那么为什么不用ToF"></a>那么为什么不用ToF</h3><p>谁说不用了？等我ToF搞定，也是要用的，小孩子才做选择题。</p><p>老子大小通吃，上下全要。</p><p>不过有一说一，为什么有了ToF还要去看毫米波雷达？</p><p>让我们来比较一下ToF和毫米波雷达的主要特性</p><table><thead><tr><th align="center"></th><th align="center">ToF</th><th align="center">毫米波雷达</th></tr></thead><tbody><tr><td align="center"><em>最大距离</em></td><td align="center">~十几米</td><td align="center"><strong>轻松过百米</strong></td></tr><tr><td align="center"><em>分辨率</em></td><td align="center"><strong>mm级</strong></td><td align="center">cm级</td></tr><tr><td align="center"><em>精度</em></td><td align="center">高</td><td align="center"><strong>更高</strong></td></tr><tr><td align="center"><em>烟雾</em></td><td align="center">严重影响</td><td align="center"><strong>毫无影响</strong></td></tr><tr><td align="center"><em>透明物体</em></td><td align="center">几近失能</td><td align="center"><strong>毫无影响</strong></td></tr><tr><td align="center"><em>测速</em></td><td align="center">-</td><td align="center"><strong>直接测量</strong></td></tr></tbody></table><p>可以看到，毫米波雷达并没有在所有领域内碾压ToF。</p><p>特别是分辨率。这是物理限制，你只能用更短的波长观察更细小的物体。但是在恶略环境，以及玻璃这种属性的物体上，毫米波完胜。</p><p>虽然毫米波雷达的绝对分辨率一般，但神奇的是它却可以检测出物体极细小的速度变化（青蛙？）这点后面会细说。</p><p>另外，还有一个也许不值一提的特性，在某些特别注重隐私的场合，ToF的“摄像头”模样大概不受欢迎。</p><p>至于价格，非常迷。基本所有国际大厂的ToF开发板的价格都很贵，而且还一副爱买不买的气派。批量价格也不算便宜，特别是分辨率稍微高一些的产品，而且还要考虑生产校准的成本。不过国产ToF上线后，这种情况会极大改观。</p><p>毫米波雷达方便，一线大厂的原厂开发板也不是遥不可及，批量价格也能接受，而且似乎有一波国产厂家也在路上。</p><hr><h3 id="为什么以前没有"><a href="#为什么以前没有" class="headerlink" title="为什么以前没有"></a>为什么以前没有</h3><p>也有，但是整个系统比较复杂和庞大，而且很贵很贵。</p><p>这两年技术进步，厂家已经可以把几乎所有的东西集成在一颗芯片里，使用常规工艺，好戏开始。</p><hr><h2 id="正题"><a href="#正题" class="headerlink" title="正题"></a>正题</h2><h3 id="集成毫米波SoC"><a href="#集成毫米波SoC" class="headerlink" title="集成毫米波SoC"></a>集成毫米波SoC</h3><p>完整的毫米波雷达系统包括：</p><ul><li>TX</li><li>RX</li><li>Clocks</li><li>ADC</li><li>MCU</li><li>DSP</li><li>,etc</li></ul><p>在高精度雷达中，有两种常见的调制技术</p><ul><li><a href="https://en.wikipedia.org/wiki/Continuous-wave_radar" target="_blank" rel="noopener"><strong>FMCW</strong></a> 连续调制</li><li><a href="https://en.wikipedia.org/wiki/Monopulse_radar" target="_blank" rel="noopener"><strong>Monopulse</strong></a> 单脉冲调制</li></ul><p>这和<a href="/archives/76aee792.html" title="TOF">TOF</a>也是惊人的相似。</p><h3 id="TI的产品线"><a href="#TI的产品线" class="headerlink" title="TI的产品线"></a>TI的产品线</h3><p>目前TI的毫米波雷达分成</p><ul><li>IWR 工业等级</li><li>AWR 汽车等级</li></ul><p>似乎是一样的，只是AWR等级的器件通过了更多车规。</p><p>以<strong>IWR1443</strong>为例</p><ul><li>IWR 代表工业级</li><li>第一位1 代表 77GHz系列， 如果是60GHz产品，会是 IWR6xxx</li><li>第二位4 代表 集成了FFT硬件加速器和MCU， 如果只有RF前端就是2， 如果是RF+MCU+DSP就是6，如果是RF+MCU+FFT+DSP就是8</li><li>第三位4 代表RX数量</li><li>第四位3 代表TX数量</li></ul><p>比如 IWR6843， 就是60Ghz射频，同时集成DSP/ FFT和MCU， 天线为3发射，4接收。</p><hr><p>在<strong>毫米波雷达</strong>的后续文章中， 将详细介绍其内在原理。</p><p>to be continued…</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;关于毫米波雷达&quot;&gt;&lt;a href=&quot;#关于毫米波雷达&quot; class=&quot;headerlink&quot; title=&quot;关于毫米波雷达&quot;&gt;&lt;/a&gt;关于毫米波雷达&lt;/h1&gt;&lt;h2 id=&quot;缘起&quot;&gt;&lt;a href=&quot;#缘起&quot; class=&quot;headerlink&quot; title=&quot;缘
      
    
    </summary>
    
    
      <category term="毫米波雷达" scheme="http://blog.tensor-robotics.com/categories/%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="雷达" scheme="http://blog.tensor-robotics.com/tags/%E9%9B%B7%E8%BE%BE/"/>
    
      <category term="毫米波" scheme="http://blog.tensor-robotics.com/tags/%E6%AF%AB%E7%B1%B3%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>闭门造车日记 第四篇</title>
    <link href="http://blog.tensor-robotics.com/archives/3d8b9fd9.html"/>
    <id>http://blog.tensor-robotics.com/archives/3d8b9fd9.html</id>
    <published>2020-04-30T12:54:10.000Z</published>
    <updated>2020-05-06T01:53:27.282Z</updated>
    
    <content type="html"><![CDATA[<h1 id="造车日记-收到驱动板"><a href="#造车日记-收到驱动板" class="headerlink" title="造车日记 - 收到驱动板"></a>造车日记 - 收到驱动板</h1><h2 id="延时"><a href="#延时" class="headerlink" title="延时"></a>延时</h2><p>快到五月份，PCB厂家的产能依然被COVID-19病毒深深影响。</p><p>日盼夜盼，延误两天。总算厂家良心，帮我免费升了航空件。</p><hr><h2 id="设计和实体同框"><a href="#设计和实体同框" class="headerlink" title="设计和实体同框"></a>设计和实体同框</h2><p><img src="3d8b9fd9/design_body.jpg" alt="真是开心呀"></p><p>除非特殊的版型，一般的长方形板，倒角的个数代表了我的重视程度。</p><ol><li>紧急的快速原型板，完全<strong>不倒角</strong></li><li>一般的设计，倒<strong>两个</strong></li><li>比较在意的设计，倒<strong>三个</strong></li><li>特别中意才会倒<strong>全部的四个</strong>角</li></ol><p><img src="3d8b9fd9/bottom.jpg" alt="背面依然是【藤原佐为】"></p><hr><h2 id="小车有了名字"><a href="#小车有了名字" class="headerlink" title="小车有了名字"></a>小车有了名字</h2><p>实在喜欢《三体》，捉摸着什么时候要再读一遍。<br>向大刘致敬。<br><img src="3d8b9fd9/name.jpg" alt="也向章北海致敬"></p><p>是的，<strong>自然选择号</strong>！</p><p>等待我喊出 <strong>“前进四”</strong> 的那一刻吧！</p><p>中二完毕……下面来仔细看看。</p><hr><h2 id="纳尼？！なに"><a href="#纳尼？！なに" class="headerlink" title="纳尼？！なに"></a>纳尼？！なに</h2><p>在检(xin)查(shang)的时候，目光突然聚焦到这个地方……</p><p><img src="3d8b9fd9/mask_error.jpg" alt="这是什么鬼"></p><p>U2芯片阻焊层错误？！赶紧打开<strong>KiCAD</strong>，对的呀。。。用的标准库。</p><p>又打开了gerberview，检查了一下也没问题。</p><p>不放心，再去生产板子的厂家下载了当时上传的工程文件核对，依然ok……</p><p>投诉！</p><p>果然是大厂，两个小时不到的功夫，二话不说，直接退款。</p><p><img src="3d8b9fd9/refund.jpg" alt="这样的厂家值得称赞"></p><p>不过好在这颗U2，是我画板子的时候拍脑袋加上去的，一枚温、湿度传感器。不是核心功能。</p><p>更何况，还有这种操作。</p><p><img src="3d8b9fd9/unmask.jpg" alt="又不是不能用"></p><p>除此之外，似乎没有其它问题…<strong>白嫖石锤</strong>……</p><p>突然之间，觉得自己有点儿不厚道 ;-)</p><hr><h2 id="一帆风顺？不存在的"><a href="#一帆风顺？不存在的" class="headerlink" title="一帆风顺？不存在的"></a>一帆风顺？不存在的</h2><p>机缘巧合之下，我读了一篇文档，就在我看到下表之后…<br><img src="3d8b9fd9/stm32f3_no_pull_up_on_usb_dp.jpg" alt="一口鲜血吐在屏幕上"></p><p>在我之前使用的所有USB芯片中</p><ul><li>上古的 PDIUSBD12</li><li>Cypress FX3</li><li>一众 USB转接芯片</li><li>等等</li></ul><p>无一例外是内建了USB DP管脚上拉电阻的。</p><p>这是USB的底层热拔插检测机制。上行端口的DP/DM被弱下拉，而一旦检测到DP或者DM脚有被1.5k电阻上拉后，就会通知USB主机进行相应的枚举操作。</p><p><strong>BUT</strong> STM32F303这个系列居然<strong>没有</strong>内置这个电阻……STM32全家都有，就这个系列没有？！哇咔咔……(V^V)</p><p>要怪也只能怪自己对STM32还是不熟，不过这也算逐步达成了既定的目标之一：通过实际项目达到对更多技术工程化水平的程度。</p><p>好在，简单飞飞线什么的，也就能搞定了。</p><h2 id="固件初步"><a href="#固件初步" class="headerlink" title="固件初步"></a>固件初步</h2><p>按住BOOT pin开关（接到+3v3），插入USB， 哈！出现了！</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">usb 1-2: new full-speed USB device number 5 using xhci_hcd</span><br><span class="line">usb 1-2: New USB device found, idVendor=0483, idProduct=df11, bcdDevice=22.00</span><br><span class="line">usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3</span><br><span class="line">usb 1-2: Product: STM32  BOOTLOADER</span><br><span class="line">usb 1-2: Manufacturer: STMicroelectronics</span><br><span class="line">usb 1-2: SerialNumber: 2049B8382031</span><br></pre></td></tr></tbody></table></figure><p>虽然来了新同事后，很久没有动过烙铁了，不过功夫还在嘛，一把成功。</p><p>随即写入恭候多时的代码框架。重启。</p><p><img src="3d8b9fd9/plugin.jpg" alt="哟西"></p><h2 id="后续进度"><a href="#后续进度" class="headerlink" title="后续进度"></a>后续进度</h2><p>五一期间不知道能捞到多少时间搞…</p><p>希望6-1之前能进入 使用遥控器 ＋ 真人▪工智能的操作模式吧。</p><p>那之后，就该去叩动<strong>vSLAM</strong>的大门。</p><p>to be continued..</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;造车日记-收到驱动板&quot;&gt;&lt;a href=&quot;#造车日记-收到驱动板&quot; class=&quot;headerlink&quot; title=&quot;造车日记 - 收到驱动板&quot;&gt;&lt;/a&gt;造车日记 - 收到驱动板&lt;/h1&gt;&lt;h2 id=&quot;延时&quot;&gt;&lt;a href=&quot;#延时&quot; class=&quot;head
      
    
    </summary>
    
    
      <category term="造车日记" scheme="http://blog.tensor-robotics.com/categories/%E9%80%A0%E8%BD%A6%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="小车" scheme="http://blog.tensor-robotics.com/tags/%E5%B0%8F%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>闭门造车日记 第三篇</title>
    <link href="http://blog.tensor-robotics.com/archives/8aa686bc.html"/>
    <id>http://blog.tensor-robotics.com/archives/8aa686bc.html</id>
    <published>2020-04-18T13:38:35.000Z</published>
    <updated>2020-04-21T05:08:46.533Z</updated>
    
    <content type="html"><![CDATA[<h1 id="造车日记-驱动板预备"><a href="#造车日记-驱动板预备" class="headerlink" title="造车日记 - 驱动板预备"></a>造车日记 - 驱动板预备</h1><p>经过几个晚上加周六断断续续的折腾， 首块驱动板终于快要问世。</p><p>下周再抽一个晚上检查检查就准备外发。实在搞不动了，明天周日好好休息一下。。</p><p>调试顺利结束后，会在github放出相关设计。</p><hr><h2 id="KiCAD已经用到炉火纯青"><a href="#KiCAD已经用到炉火纯青" class="headerlink" title="KiCAD已经用到炉火纯青"></a>KiCAD已经用到炉火纯青</h2><p>原理图继续采用结构化（自顶向下）设计。</p><p><img src="8aa686bc/sch_top.jpg" alt="非常喜欢这种方式，取代了之前的平铺地板流"></p><h2 id="STM32持续熟悉中"><a href="#STM32持续熟悉中" class="headerlink" title="STM32持续熟悉中"></a>STM32持续熟悉中</h2><hr><p>这是第一次完全独立使用STM32（之前有过一次，但是更多是依据参考设计）。</p><p>相比用了好多年的AVR XMEGA，无论内核还是外设，都是碾压式超越，就算考虑到性价比，可能也是被完胜。</p><p>不过也更复杂一些，有一些外设，我专门花了两天时间去看文档，还是有点儿稀里糊涂的感觉。</p><p><strong>XMEGA</strong>比STM32好的地方之一，是它的外设、寄存器规划得都非常整齐，使用、记忆起来极其方便。STM32的规划完全就是<strong>一坨屎</strong>……</p><p>不服来辩。</p><p>当然ST自己也是知道这种鬼情况的，所以搞出一套CUBEMX，使用起来还算愉快。</p><p>基本上，外设规划能做到可视化，初始代码生成器也工作良好。</p><p><img src="8aa686bc/cube_io.jpg" alt=""></p><hr><h2 id="电源"><a href="#电源" class="headerlink" title="电源"></a>电源</h2><p>本来计划只用一颗开关电源，降压到５ｖ，后来发现目前计划使用的<strong>RK3399</strong>，上面有一些电路不能直接工作在超过１６ｖ电压，而且万一以后要换用别的板子，说不定也要用到１２ｖ，所以最终用了两颗MPS <strong>MP8715</strong>。</p><p>这是一种同步整流DCDC，４Ａ持续能力，并且拥有100%占空比。因为电池的电压大致在１２ｖ～１６．８ｖ，普通的电源芯片有可能在低压条件下无法正常输出。</p><p>系统５ｖ的使能接上拉，并且留了一个开关，可以接地关机。</p><p>１２ｖ供电的使能由５ｖ上拉，同时接入单片机的OC输出，允许单片机控制。</p><h2 id="充电口"><a href="#充电口" class="headerlink" title="充电口"></a>充电口</h2><p>充电口使用了理想二极管控制电路，保证充电触电上不会有电压，直接短路也没事儿。同时有充电信号告知单片机。</p><h2 id="其它电路"><a href="#其它电路" class="headerlink" title="其它电路"></a>其它电路</h2><ul><li>整机放电电流检测</li><li>电池电压检测</li><li>ws2813驱动</li><li>蜂鸣器</li><li>SHT30温度和湿度度传感器</li></ul><h2 id="Layout"><a href="#Layout" class="headerlink" title="Layout"></a>Layout</h2><p>电子是自学的，不专业，不过画图，我是认真的。<br>当然在内心深处，我一直觉得自己是程序员。<br>所以，懂的，还请多多指教。</p><p><img src="8aa686bc/drv_board_top.jpg" alt="顶层"></p><p>得到MPS的芯片赞助，顺手板子上打个广告。</p><p>脑残粉得到主的恩典，开心^_^</p><p><img src="8aa686bc/drv_board_b.jpg" alt="底层"></p><p><img src="8aa686bc/layers.gif" alt="内层"></p><hr><p>今天就水一番，实在太累了。。。</p><p>to be continued..</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;造车日记-驱动板预备&quot;&gt;&lt;a href=&quot;#造车日记-驱动板预备&quot; class=&quot;headerlink&quot; title=&quot;造车日记 - 驱动板预备&quot;&gt;&lt;/a&gt;造车日记 - 驱动板预备&lt;/h1&gt;&lt;p&gt;经过几个晚上加周六断断续续的折腾， 首块驱动板终于快要问世。&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="造车日记" scheme="http://blog.tensor-robotics.com/categories/%E9%80%A0%E8%BD%A6%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="小车" scheme="http://blog.tensor-robotics.com/tags/%E5%B0%8F%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>闭门造车日记 第二篇</title>
    <link href="http://blog.tensor-robotics.com/archives/c7b825ee.html"/>
    <id>http://blog.tensor-robotics.com/archives/c7b825ee.html</id>
    <published>2020-04-08T12:21:57.000Z</published>
    <updated>2020-04-10T02:04:14.819Z</updated>
    
    <content type="html"><![CDATA[<h1 id="造车日记-驱动板规划"><a href="#造车日记-驱动板规划" class="headerlink" title="造车日记 - 驱动板规划"></a>造车日记 - 驱动板规划</h1><h2 id="总线之首选-gt-EtherCAT"><a href="#总线之首选-gt-EtherCAT" class="headerlink" title="总线之首选 -> EtherCAT"></a>总线之首选 -&gt; EtherCAT</h2><p>久闻 <a href="https://www.ethercat.org/" target="_blank" rel="noopener">EtherCAT</a>大名，想着就以帅的名义学习一番，看看能不能用作小车的内部主干总线。</p><p>经过几个晚上的学习，大概摸清了Ethercat的毛皮。</p><p>EtherCAT， 是一个以以太网为基础的工作现场总线。它完全沿用了<a href="https://en.wikipedia.org/wiki/Ethernet" target="_blank" rel="noopener">以太网</a>的物理层，并延续了标准的<a href="https://en.wikipedia.org/wiki/Ethernet_frame" target="_blank" rel="noopener">以太帧</a>，但后面的使用上则完全不同。</p><hr><h3 id="常规以太网"><a href="#常规以太网" class="headerlink" title="常规以太网"></a>常规以太网</h3><p>在常规的以太网中，并没有中心节点，每个节点都可以占用网络，并相应发展出载波监听/冲突检测技术，当多个节点同时想收发信息时，必定会有不确定的延时。</p><p>此外虽然以太网的基础速率较高，但是对于高频次的短小消息来说，整体总线利用率可以说非常低（2-5%）</p><hr><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>在一个EtherCAT网络有且只有唯一的<strong>主站</strong>，<strong>从站</strong>节点则可以多达六万多个。而网络利用率却可以达到~97%，同时，从站间的同步偏差小于1us，在包含100个伺服轴节点的系统中，可以以10kHz的速度更新它们的状态信息。</p><p>这对于一个有众多执行机构，并且需要可控同步的机器人系统来说太美好了。</p><p>基本上主站的网络设备可以使用常规的以太网卡。EtherCAT改造的是从站节点的“网卡”。</p><p>在EtherCAT中每个从节点都有一个特制的网卡，该卡有2个独立的port（也有的有3个）。其中一个连接上行设备（或者主站），另外一个连接下行设备（或者留空）。</p><p>EtherCAT子设备网卡，支持一种被称为“Processing On the Fly”的技术，当一个从站收到上游发来的数据时，立即在硬件上将属于自己的数据更新，并立刻从下游端口发出新的数据。</p><p>维基百科上的一个动图很好的解释了这一点。<br><img src="c7b825ee/EthercatOperatingPrinciple.svg" alt=""></p><hr><h3 id="网卡"><a href="#网卡" class="headerlink" title="网卡"></a>网卡</h3><p>从站的EtherCAT网络方案有大概三种</p><ul><li>SOC， ARM核心带ethercat控制器</li><li>FPGA Core</li><li><strong>收发器</strong></li></ul><p>使用SoC的芯片应该是更合理的方式，不过当前支持EtherCAT的SoC并不算多，所以我重点看了两款独立的收发器芯片，这样搭配自己的处理器会灵活一些。</p><ul><li>LAN9252</li><li>AX58100</li></ul><p>基本大同小异吧， 以AX58100为例， 内部框图如下<br><img src="c7b825ee/ax58100_block.jpg" alt=""></p><p>典型系统构成<br><img src="c7b825ee/ethercat_system.jpg" alt=""></p><p>感觉开发从站的话应该只是工作量的问题，并没有明显障碍。</p><hr><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>目前为止，一起都很美好，除了EtherCAT的性能对于一个玩具小车来说有些overkill。</p><p>直到我大略的看了一下<strong>主站方案</strong>……问题出来了。</p><p>似乎主流的Linux主站方案都停留在2013年左右，对LinuX内核支持停留在 2.6/3.x的时代，而我电脑目前的内核版本是5.5.9……</p><p>更为头疼的是因为EtherCAT的实时性非常高，似乎如果主站不是实时操作系统的话，从节点会因为得不到及时相应而罢工……</p><p>看了一圈，似乎目前的方案是引入这个项目</p><p><strong><a href="https://gitlab.denx.de/Xenomai/xenomai/-/wikis/home" target="_blank" rel="noopener">Xenomai</a></strong></p><p>这是一个让计算机运行双内核的东西。标准LinuX内核+实时内核。</p><p>这玩笑就开大了……完全搞定这个，似乎研究生都能毕业一回。而我要的只是一个能控制小车的总线……</p><hr><h3 id="最终选择"><a href="#最终选择" class="headerlink" title="最终选择"></a>最终选择</h3><p>EtherCAT性能确实优异，看上去也很好玩，再合适的场景下确实相当帅。</p><p>我会继续看下去，但是恐怕不是在小车这个东西上了。</p><p>所以最终，小车的主控（暂定RK3399）和电机板之间的总线为</p><p><strong>USB</strong></p><hr><h2 id="驱动板MCU"><a href="#驱动板MCU" class="headerlink" title="驱动板MCU"></a>驱动板MCU</h2><p>这里先透露一下 <strong><a href="https://blog.tensor-robotics.com/categories/FoC/">FoC计划</a></strong> 的首款PCB<br><img src="c7b825ee/stm32-foc-v1.jpg" alt=""></p><p>小车的话，打算采用同款MCU <strong>STM32F303RET6</strong></p><p>有四个QD，在CubeMX里试了一下，有足够的资源硬件解码。<br><img src="c7b825ee/cube_qd.jpg" alt=""></p><p>USB也靠它片上实现</p><p>此外8根PWM，驱动电机</p><p>说不定灯效也放在它身上，到时候看</p><hr><h2 id="电机驱动器"><a href="#电机驱动器" class="headerlink" title="电机驱动器"></a>电机驱动器</h2><p>作为MPS脑残粉，电源、驱动之类的肯定首选MPS。</p><p>本来看中 <strong><a href="https://www.monolithicpower.com/en/mp6519.html" target="_blank" rel="noopener">MP6519</a></strong> </p><p>这是一颗28v 5A的可控恒流源。本来想着可以对付因为感抗造成的DC启动性能差的问题，不过后经高人提醒，电机的调速用电流源的话，会非常不线性。</p><p>最后基本确定为 <strong>MP6612</strong> 这颗。</p><hr><p>不日将开工画板。</p><p>to be continued..</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;造车日记-驱动板规划&quot;&gt;&lt;a href=&quot;#造车日记-驱动板规划&quot; class=&quot;headerlink&quot; title=&quot;造车日记 - 驱动板规划&quot;&gt;&lt;/a&gt;造车日记 - 驱动板规划&lt;/h1&gt;&lt;h2 id=&quot;总线之首选-gt-EtherCAT&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
    
      <category term="造车日记" scheme="http://blog.tensor-robotics.com/categories/%E9%80%A0%E8%BD%A6%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="小车" scheme="http://blog.tensor-robotics.com/tags/%E5%B0%8F%E8%BD%A6/"/>
    
      <category term="EtherCAT" scheme="http://blog.tensor-robotics.com/tags/EtherCAT/"/>
    
  </entry>
  
  <entry>
    <title>闭门造车日记 第一篇</title>
    <link href="http://blog.tensor-robotics.com/archives/f7aec936.html"/>
    <id>http://blog.tensor-robotics.com/archives/f7aec936.html</id>
    <published>2020-03-29T06:31:39.000Z</published>
    <updated>2020-04-28T06:29:08.788Z</updated>
    
    <content type="html"><![CDATA[<h1 id="造车日记-开篇"><a href="#造车日记-开篇" class="headerlink" title="造车日记 - 开篇"></a>造车日记 - 开篇</h1><h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><p>看到<a href="https://www.dji.com/cn/robomaster-s1" target="_blank" rel="noopener">大疆 RoboMaster S1</a>之后，就有了自己也做一台小车的想法。</p><p>当然除了以后给女儿当玩具玩儿之外，目的还是非常明确的。</p><h3 id="在硬件层面"><a href="#在硬件层面" class="headerlink" title="在硬件层面"></a>在硬件层面</h3><p>主要是尝试新技术以及为一些技术的工程化积累经验。包含但不限于</p><ul><li>CAN/ Ethercat 等现场总线</li><li>高等级嵌入式芯片和开发</li><li>各种新传感器</li></ul><h3 id="在软件层"><a href="#在软件层" class="headerlink" title="在软件层"></a>在软件层</h3><p>有一个专一但是庞大的目标：实践<a href="https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping" target="_blank" rel="noopener">vSLAM</a></p><p>在目前已知的室内定位技术中，总感觉 基于RGB-D的vSLAM是才王道，其它都是异端，虽然异端也有异端的作用。</p><hr><h2 id="首批硬件"><a href="#首批硬件" class="headerlink" title="首批硬件"></a>首批硬件</h2><h3 id="底盘"><a href="#底盘" class="headerlink" title="底盘"></a>底盘</h3><p>最近工作原因多少接触了一些CAD软件，本来想着自己从头画图开料，但是毕竟不是本行，时间花在这个上面不是太划算，于是就花了几个晚上逛了逛 <del>窑子</del> 不对淘宝。终于找到了还算满意的小平台。四麦克纳姆轮。</p><p><img src="f7aec936/chassis.jpg" alt=""></p><p>和老板哭了一会儿穷（真穷），饶了我￥40块，尽管如此，心还是在滴血…</p><p><img src="f7aec936/b_joint.jpg" alt=""></p><p>底部的一个设计还是挺好的，虽然买不起四轴独立悬架版本，好歹有一个低成本板车方案 ^_^</p><p>因为成本问题， 这版就先用有刷电机，等我FoC完全整明白了， 再给换装无刷电机。</p><h3 id="动力电池"><a href="#动力电池" class="headerlink" title="动力电池"></a>动力电池</h3><p><img src="f7aec936/batt.jpg" alt=""></p><p>采用了特斯拉 3系同款的 <strong>21700</strong>电芯，4s2p结构。相比比传统的18650电池</p><ul><li>价格更低</li><li>容量更高</li><li>内阻更低</li><li>一致性更好</li><li>寿命更长</li></ul><p>原打算自己做BMS的，后来想想，一共就8颗电芯，好像啥管理必要了，直接让卖家给我封了一块充放电同口的保护板进去了事。￥170块。</p><h3 id="遥控"><a href="#遥控" class="headerlink" title="遥控"></a>遥控</h3><p>第一阶段的调试，也是为了好玩，一个能直接用的手柄还是需要的。<br><img src="f7aec936/remote_ctrl.jpg" alt=""></p><p>taobao又搜了一个晚上，发现这个。乐视的手柄。虽然我对乐视完全无感，但是￥40块钱，无线，还能说啥。</p><p>然后，到手之后发现， 手感还不错。就是有一个按键不太灵光，和老板反应了，他居然说要不就退款，这个就算送给我，要不就再给我寄一个，这个也送给我。。。</p><p>那个坏的键， 我拆开看过， 其实内部开关都是好的， 就是模具有点儿问题， 中间垫个纸片就几乎完美。于是我花了￥40块买了两个手柄。</p><p>这个手柄在LinuX可以使用大部分功能，目前震动还不知道怎么搞出来，似乎不是标准协议…问题不大。</p><h3 id="主控（暂定）"><a href="#主控（暂定）" class="headerlink" title="主控（暂定）"></a>主控（暂定）</h3><p>RK3399</p><p><img src="f7aec936/rk3399.jpg" alt=""></p><p>双摄也有，倒是看看同步的情况，以及适合不适合跑slam。</p><hr><h2 id="下一步计划"><a href="#下一步计划" class="headerlink" title="下一步计划"></a>下一步计划</h2><h3 id="规划驱动板，选定互联总线，用遥控器自由控制"><a href="#规划驱动板，选定互联总线，用遥控器自由控制" class="headerlink" title="规划驱动板，选定互联总线，用遥控器自由控制"></a>规划驱动板，选定互联总线，用遥控器自由控制</h3><h3 id="开始构建和实践SLAM"><a href="#开始构建和实践SLAM" class="headerlink" title="开始构建和实践SLAM"></a>开始构建和实践SLAM</h3><h3 id="其它好玩儿的附加功能"><a href="#其它好玩儿的附加功能" class="headerlink" title="其它好玩儿的附加功能"></a>其它好玩儿的附加功能</h3><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;造车日记-开篇&quot;&gt;&lt;a href=&quot;#造车日记-开篇&quot; class=&quot;headerlink&quot; title=&quot;造车日记 - 开篇&quot;&gt;&lt;/a&gt;造车日记 - 开篇&lt;/h1&gt;&lt;h2 id=&quot;缘起&quot;&gt;&lt;a href=&quot;#缘起&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
    
      <category term="造车日记" scheme="http://blog.tensor-robotics.com/categories/%E9%80%A0%E8%BD%A6%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="分享和生产知识" scheme="http://blog.tensor-robotics.com/tags/%E5%88%86%E4%BA%AB%E5%92%8C%E7%94%9F%E4%BA%A7%E7%9F%A5%E8%AF%86/"/>
    
      <category term="小车" scheme="http://blog.tensor-robotics.com/tags/%E5%B0%8F%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>安德猴的另类玩法</title>
    <link href="http://blog.tensor-robotics.com/archives/75e36441.html"/>
    <id>http://blog.tensor-robotics.com/archives/75e36441.html</id>
    <published>2020-03-24T12:41:59.000Z</published>
    <updated>2020-03-29T08:15:18.167Z</updated>
    
    <content type="html"><![CDATA[<p>要耍安德猴，可以</p><ul><li>在装有android的平板、手机上使用</li><li>可以用android sdk自带的模拟器（基于qemu）</li><li>还可以使用virtualbox/ vmware这样的虚拟机运行x86 android</li></ul><p>体验从上到下， 依次80分，50分和10分。（iPhone是 100分的话）</p><hr><p>本文介绍一种新的方式，将安卓置于Linux内核原生的容器（container）中，具有基本的GPU硬件加速，同时自带android的核心系统服务。</p><p>说人话，就是让android app原生的运行在一台PC中</p><p>仿佛有一台android设备运行在电脑里一样。但是并不是虚拟机或者模拟器，所以速度很快。</p><p>初步体验， 可以打到60~70分。</p><hr><p>主角： <a href="http://anbox.io" target="_blank" rel="noopener"><strong>ANBOX</strong></a></p><hr><p>官方网站的安装说明已经非常详细，这里只是大概记录一下。</p><p>首先Debian源里的并不是新版本，官方目前只支持snap包管理系统，所以如果你的Debian里还没有snap的话需要</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install snapd</span><br></pre></td></tr></tbody></table></figure><hr><p>Anbox安装</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo snap install --devmode --beta anbox</span><br></pre></td></tr></tbody></table></figure><p>如果日后需要更新</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo snap refresh --beta --devmode anbox</span><br></pre></td></tr></tbody></table></figure><p>snap在国内访问会非常不和谐，但是snap又不能直接使用环境变量， 需要修改其配置</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl edit snapd.service</span><br></pre></td></tr></tbody></table></figure><p>修改或加入下面几行</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">Environment=http_proxy=http://127.0.0.1:8123</span><br><span class="line">Environment=https_proxy=http://127.0.0.1:8123</span><br></pre></td></tr></tbody></table></figure><hr><p>Anbox内核模块安装</p><p>需要首先apt安装 dkms和内核头文件。</p><p>之后从git clone内核模块的源代码</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/anbox/anbox-modules.git</span><br></pre></td></tr></tbody></table></figure><p>编译</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo cp -rT ashmem /usr/src/anbox-ashmem-1</span><br><span class="line">sudo cp -rT binder /usr/src/anbox-binder-1</span><br><span class="line">sudo dkms install anbox-ashmem/1</span><br><span class="line">sudo dkms install anbox-binder/1</span><br></pre></td></tr></tbody></table></figure><p>加载测试</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo modprobe ashmem_linux</span><br><span class="line">sudo modprobe binder_linux</span><br></pre></td></tr></tbody></table></figure><p>正常情况下，lsmod应该就能看到刚刚加载的模块</p><p>/dev/下面也会出现对应的设备</p><ul><li>/dev/binder</li><li>/dev/ashmem</li></ul><p>需要修改这两个文件的访问权限， 让普通用户也能访问。</p><hr><p>激动人心的时刻， 运行</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anbox.appmgr</span><br></pre></td></tr></tbody></table></figure><p>第一次运行的话， CPU会加载android的系统环境， 在我电脑上大概几秒吧 ，完了之后就能看到一个新窗口<br><img src="75e36441/anbox_appmgr.jpg" alt=""></p><p>点开里面原生自带的应用，每一个都会是一个独立的窗口。</p><hr><p>这时可以用adb shell连进去看看。<br><img src="75e36441/adb_shell.jpg" alt=""></p><p>可以看到android显示的内核、硬件都是真机的，这就是Linux内核容器。</p><p>不要惊讶分辨率，我用的是1440p+1080p双显示器</p><p>此时android会用以太网卡和主机连接，而在主机端呢， 刚刚的内核驱动则会虚拟出一个anbox0网络设备。</p><hr><p>不爽之处</p><ul><li>目前的img只有 7.1</li><li>似乎并不支持摄像头</li></ul><hr><p>喔，对了， 有个脚本可以给默认的android image添加上google play，安装app方便很多</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/geeks-r-us/anbox-playstore-installer.git</span><br></pre></td></tr></tbody></table></figure><p><img src="google-play.jpg" alt=""></p><hr><p>就到这里，</p><p>下次再见。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;要耍安德猴，可以&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在装有android的平板、手机上使用&lt;/li&gt;
&lt;li&gt;可以用android sdk自带的模拟器（基于qemu）&lt;/li&gt;
&lt;li&gt;还可以使用virtualbox/ vmware这样的虚拟机运行x86 android&lt;/li&gt;

      
    
    </summary>
    
    
      <category term="CS" scheme="http://blog.tensor-robotics.com/categories/CS/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="android" scheme="http://blog.tensor-robotics.com/tags/android/"/>
    
      <category term="安德猴" scheme="http://blog.tensor-robotics.com/tags/%E5%AE%89%E5%BE%B7%E7%8C%B4/"/>
    
      <category term="anbox" scheme="http://blog.tensor-robotics.com/tags/anbox/"/>
    
  </entry>
  
  <entry>
    <title>ST MCSDK 的开箱使用 | 电机系列 第二篇</title>
    <link href="http://blog.tensor-robotics.com/archives/b19fd6ba.html"/>
    <id>http://blog.tensor-robotics.com/archives/b19fd6ba.html</id>
    <published>2020-03-23T14:13:04.000Z</published>
    <updated>2020-03-29T08:11:55.329Z</updated>
    
    <content type="html"><![CDATA[<p>因为工作的关系，接触到一些电机的驱动。最早是BLDC，跟着老工程师后面，从懵懵懂懂，到稍微有了一点儿概念。之后自己憋出一个能走微步的步进电机驱动。满满的成就感记忆犹新。</p><p>后面的项目，用集成驱动芯片独立完成了一些其它的电机驱动。</p><p>前二年的学习过程中，听说了FOC这个词，似乎各种厉害各种邪乎。</p><hr><p><img src="b19fd6ba/foc_feature.jpg" alt=""></p><p>于是各种买书，各种懵逼。心潮澎湃想自己从零实现一整套，搞了一段时间，越搞坑越深，最后FOC没搞出来，传统六步方波式的驱动器倒是攒出来。不甘心啊。</p><p>也有一些优秀的厂家提供了不错的集成方案，套片解决问题，不过因为项目使用限制，虽然已经调通了demo但是并没有实际使用上。</p><p>9102年就要过去，年初制定的年度计划眼看着又有一项要完不成（为什么说”又”呢。。。淡淡的忧伤……）</p><p>突然得知ST的电机驱动库发布了重要的更新，并且全部开源（有一定限制）。抓着最后几周，调通demo。并且有继续深入下去的可能了。</p><p>////<br>本番废话略多，下面进入正题。<br>////</p><hr><p>相比六步方波，FOC驱动中包含诸如Park/Clark变换等带有大量三角函数的矩阵计算，以前的8/16单片机就有些捉襟见肘（XMEGA系列处于勉强够用的边缘）。</p><p>因此这里选择了STM32F303REt6作为主控。72Mhz 带硬件数学单元的Cortex M4算力够强，此外它内建了为高阶电机驱动优化过的定时器，特别是还集成了大量的模拟比较器，运算放大器和ADC。将来自己做PCB的话，只要配合桥驱动器和mosfet就可以。</p><p>ST 提供的MCSDK提供了FOC的底层库，以及一些实用程序。ST官网给出了两个版本，MCSDK，以及MCSDK-FULL，二者的区别是MCSDK中的部分高阶算法（比如状态观测器、前馈控制等）只以二进制库的方式提供，而full的版本则包含全部的源代码。</p><p>可能是刚刚出新的原因，目前MCSDK仅提供了m$ windows版本，只能在虚拟机里搞搞，不过ST承诺会在2020年推出重构的MCSDK，将全平台支持。</p><p><img src="b19fd6ba/linux_version.jpg" alt=""></p><hr><p>装好后，得到一些新图标</p><p><img src="b19fd6ba/icon.jpg" alt=""></p><hr><p>使用Keil/IAR等其它ide的，STM32CUBEIDE就不再需要。重要的是左边上下的两个。Motor Profiler和 MotorControl Workbench</p><p>Motor Profiler是一套很好玩儿的实用程序。它使用内置的固件（因此目前只能支持官方开发板）自动侦测电机的各种参数，以待后用。</p><p>打开它，界面如下</p><p><img src="b19fd6ba/gui.jpg" alt=""></p><hr><p>选择好手上的控制板和驱动后，需要填写电机极对数，不知道的话可以用下面的方法测定：<br>使用恒流源接入电机的任意两相，然后手动转动电机转子一圈，边转边计数有几次咯噔咯噔（术语：掣子），如果是4次，那么电机就是4对磁极。</p><p>如果使用的驱动板能力远远大过电机或者电源的额定电流，需要正确填写电机的最大电流，否则驱动板会尝试使用很大的电流测试电机。</p><p>剩下的参数，可填可不填。</p><p>完了就可以点击connect和Start Profile。<br>程序会先后测定电机的</p><ul><li>相 电阻</li><li>相 电感</li><li>反电动势常数</li><li>转动惯量</li><li>机械摩擦系数</li></ul><p>将测定参数命名后保存待用。</p><hr><p>接下来打开Motor Control Workbench这个程序， 并选择新建一个项目</p><p><img src="b19fd6ba/mc_wb.jpg" alt=""></p><p>与Motor Profiler不同，workbench是支持自定义板级的，这里还是先用开发板</p><p>配置核心在此。<br><img src="b19fd6ba/mc_wb_config.jpg" alt=""></p><p>这里可以选择底层驱动相关的各种参数，包括：</p><ul><li>母线电压相关</li><li>温度监控相关</li><li>制动器相关</li><li>电机选择（这里可以使用刚刚用Motor Profiler测量的参数，也可以- 根据电机厂商的datasheet直接填写）</li><li>驱动桥相关</li><li>电流检测配置</li><li>速度、位置检测配置</li><li>IO/模拟电路配置</li><li>等等</li></ul><hr><p>根据硬件配置好后，就可以电机生成按钮，生成配置好的初始化框架。然后点击Run Cube。进一步配置和MCSDK无关的其它CUBE配置。<br>常规的cube配置完成后，再点击gennerate code就完成的所有外设，和库的初始化代码， 以及一个空的 main() （如果没有配置freeRTOS的话）</p><p>我一开始下载的版本是 5.4.1， 配合cube的常规固件库 stm32f303 1.10.0，经常会出现一些奇奇怪怪的问题，这个不能编译，那个少个依赖什么的。</p><p>后来更新到了 5.4.3似乎好了一点儿。。但是总是很悬的感觉。因为就算是5.4.3生成出来的代码，我也是修改了一点点东西才能编译……还是期望Linux版本早点儿出来吧。。。</p><p>ST还提供了测试界面， 如果代码生产正常，就可以简单驱动起来。</p><p><img src="b19fd6ba/run.jpg" alt=""></p><p>能够正确编译以后，就可以把代码拷出虚拟机，转到Linux真机后续开发，只要不动mcsdk的结构配置，倒也不再需要虚拟机。</p><p>后续将结合FOC一起介绍MCSDK的结构和开发过程。</p><p>本番结束。<br>to be continued</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;因为工作的关系，接触到一些电机的驱动。最早是BLDC，跟着老工程师后面，从懵懵懂懂，到稍微有了一点儿概念。之后自己憋出一个能走微步的步进电机驱动。满满的成就感记忆犹新。&lt;/p&gt;
&lt;p&gt;后面的项目，用集成驱动芯片独立完成了一些其它的电机驱动。&lt;/p&gt;
&lt;p&gt;前二年的学习过程中
      
    
    </summary>
    
    
      <category term="FoC" scheme="http://blog.tensor-robotics.com/categories/FoC/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="FoC" scheme="http://blog.tensor-robotics.com/tags/FoC/"/>
    
      <category term="电机驱动" scheme="http://blog.tensor-robotics.com/tags/%E7%94%B5%E6%9C%BA%E9%A9%B1%E5%8A%A8/"/>
    
  </entry>
  
  <entry>
    <title>DIY 示波器电流探头 | 电机系列 第一篇</title>
    <link href="http://blog.tensor-robotics.com/archives/c122089a.html"/>
    <id>http://blog.tensor-robotics.com/archives/c122089a.html</id>
    <published>2020-03-23T13:18:57.000Z</published>
    <updated>2020-03-29T08:11:34.972Z</updated>
    
    <content type="html"><![CDATA[<p>最近项目需要用到电流探头， 某宝一搜，心凉半截。国产靠谱品牌，最便宜的都要￥3、4000。性能略强一些的， 都得成倍成倍的往上翻。一年可能也就用那么十次八次，也不太好意思申请购买 卍</p><p><img src="c122089a/strobe.jpg" alt=""></p><p>正巧， 前段时间有收到 电子发烧友 送测的 MAX40056 EVKIT，脑袋一拍，计上心头。</p><p><img src="c122089a/max40056.jpg" alt=""></p><hr><p>美信的MAX40056是一颗 双向电流采样放大器。共模输入上限达到接近70伏，并且内建反向过冲电压防护。提供50V/V, 20V/V, 10V/V三种增益倍率的封装。</p><p>比起一般的差分放大器，这颗芯片采用针对性的技术，可以抑制PWM信号带来的噪声干扰。</p><p>MAX40056也集成了+1.5v的精密基准源，配合+3.3v单电源使用非常简单。</p><p><img src="c122089a/max40056_block.jpg" alt=""></p><hr><p>根据内部框图， 可以看到还具有快速过流保护功能。</p><p>因此这颗芯片非常适合高阶电机驱动的电流采样方案。</p><p>一般电流采样方案使用低位电阻，好处是便宜，坏处是运放同样靠近地，噪声会比较大</p><p>稍微高级一点儿， 使用高位电阻配合高共模放大器，略贵一点儿的价格带来更干净的信号，同时有一个额外的好处是可以检测到负载的对地短路事件。</p><p>但是简单的电阻采样无论高低位都一个弊端， 在桥式结构的电路中电流采样都会存在窗口期， 需要精确配合pwm。</p><p>而使用更高级的 相电流采样 方案，则完全没有这个问题，可以在任何时段内采集电流。除了更贵一丢丢外，全是优点，没有任何缺点。</p><p>MAX40056 就可以这样用。</p><p>300kHz(-3dB)的 带宽， 刚好也和最低档次的CT探头一样规格。</p><hr><p>////<br>话不多说，直接开搞。<br>////</p><p>内部 +1.5v 电压基准。</p><p><img src="c122089a/ref_voltage.jpg" alt=""></p><p>原板的采样电阻为 R050， 再加上 MAX40056F的增益是 50V/V， 所以默认配置只能采集 +/- 0.7A的电流， 果断拆了……<br>大厂原版开发板，就是严谨。教科书级的开尔文布线。</p><p><img src="c122089a/layout.jpg" alt=""></p><p>换上小十倍的电阻， 采样量程扩大10倍。当然精度也随之下降。</p><p><img src="c122089a/resistance.jpg" alt=""></p><p>完整的采样测试电路</p><p>便利性和成品CT探头肯定要差， 精度应该不落太多。</p><p>差着100+倍的成本 (=@__@=)</p><p><img src="c122089a/circuit.jpg" alt=""></p><p>四通道示波器终于派上大用场。</p><p>要用的时候，它就在那儿，的感觉真好。<br>foc扭矩控制，单相电流终于有点儿正弦波的样子了￼￼！<br>老子等这天好久好久了￼<br>工具在手，天下我有！</p><p><img src="c122089a/foc-1/scope.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近项目需要用到电流探头， 某宝一搜，心凉半截。国产靠谱品牌，最便宜的都要￥3、4000。性能略强一些的， 都得成倍成倍的往上翻。一年可能也就用那么十次八次，也不太好意思申请购买 卍&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;c122089a/strobe.jpg&quot; alt=&quot;&quot;&gt;
      
    
    </summary>
    
    
      <category term="FoC" scheme="http://blog.tensor-robotics.com/categories/FoC/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="FoC" scheme="http://blog.tensor-robotics.com/tags/FoC/"/>
    
      <category term="电机驱动" scheme="http://blog.tensor-robotics.com/tags/%E7%94%B5%E6%9C%BA%E9%A9%B1%E5%8A%A8/"/>
    
  </entry>
  
  <entry>
    <title>关于ToF 番四</title>
    <link href="http://blog.tensor-robotics.com/archives/76aee792.html"/>
    <id>http://blog.tensor-robotics.com/archives/76aee792.html</id>
    <published>2020-03-22T08:51:06.000Z</published>
    <updated>2020-03-29T08:08:41.680Z</updated>
    
    <content type="html"><![CDATA[<p>由于各种原因，和本番相关的工作被严重耽误……以至于错过大好机会</p><p><strong>痛定思痛 痛何如哉</strong></p><hr><p>本番行文后，将在另外一种形式上重启</p><hr><p>在 【关于ToF 番二】 中介绍的ToF系统，使用连续调制光照射外界，并通过多帧数据，计算得出反射光的相位偏移角度， 从而间接计算出光线行走距离。</p><p>但，这不是唯一的方式，本文介绍另外一种ToF相机的操作原理：脉冲式ToF</p><p>让我们来构建一个和连续调制方式ToF的有点儿相似但不完全相同的像素结构</p><p><img src="76aee792/pulse_tof_gate.webp" alt=""></p><ul><li>首先操作时， chg会打开，对两侧两颗电容充电</li><li>然后S0(或S1)进行开关操作，开关时机由调制模块控制</li><li>像素点开始曝光，并将光信号转变成电荷</li><li>当S0（或S1）闭合时，积分电荷就会和对应电容中和</li><li>最后读取电容中的剩余电压</li></ul><p>然后有下图</p><p><img src="76aee792/op.webp" alt=""></p><ul><li>第一行 代表受控的LED输出，正是因为这个，才被称之为脉冲式</li><li>第二行 代表实际的光线反射回波</li></ul><hr><p>LED发射的每个脉冲长度为 t， 而S0和S1的采样时长也为t，但是S0于LED同时开启，S1在S0关闭后立即打开。因此得到第三行和第四行</p><ul><li>第三行 是S0的积分</li><li>第四行 是S1的积分</li></ul><p>得到公式</p><p> d = 1/2 * C * t * (S0) / (S0 + S1)</p><p>可以看到，和连续调制ToF相比</p><ul><li>脉冲ToF的结算会更容易。当然二者基本还是在一个水平线上，一个是加减乘除，一个带三角函数</li><li>连续调制ToF的像素点因为是差分结构，对环境光噪音的抑制有天生的优势</li><li>听说脉冲式ToF的精度会略高，当然还要看各自厂家的具体优化手段</li><li>连续调制ToF在计算中，可以得到一些附结论（比如误差估计）</li></ul><hr><p>最后附上一种连续调制式ToF的像素结构图</p><p><img src="76aee792/tune.jpeg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;由于各种原因，和本番相关的工作被严重耽误……以至于错过大好机会&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;痛定思痛 痛何如哉&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本番行文后，将在另外一种形式上重启&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;在 【关于ToF 番二】 中介绍的ToF系统，使用连续调制
      
    
    </summary>
    
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/categories/ToF/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/tags/ToF/"/>
    
  </entry>
  
  <entry>
    <title>关于ToF 番三</title>
    <link href="http://blog.tensor-robotics.com/archives/3a7c8b8c.html"/>
    <id>http://blog.tensor-robotics.com/archives/3a7c8b8c.html</id>
    <published>2020-03-22T08:03:06.000Z</published>
    <updated>2020-03-29T08:08:24.960Z</updated>
    
    <content type="html"><![CDATA[<p>由于各种事物影响， ToF项目被暂缓了￼， 趁着公司再次搬家的这段时间，重新捡起来。</p><iframe frameborder="0" src="https://v.qq.com/txp/iframe/player.html?vid=o1357dpu781" allowfullscreen="true"></iframe><p>先是把代码又理了一遍，抽空学习了一下numpy， 搞一点儿opencv，tensorflow和pytorch，把第二编辑器换成了VSCode（顺便看了一下markdown和简单的Latex语法），换用Python 3.7，还有vrep， openscad，steamVR HDK什么的……咦，好像扯远了……然后继续攻目前的障碍。这把终于弄通了￼ 其实很简单的嘛。。。。</p><hr><p>非英语母语国家的厂家写的英文文档遇上了半吊子英语水平的我的结果是世界上最远的距离变成了本来往后退一步就能到达的地方却要拼命往前跑￼</p><p>是的，我看文档时就和你读上句话的感受是一样的￼</p><p><img src="3a7c8b8c/blurred.webp" alt=""><br> 这是我用mardkdown做的笔记， 数学公式真的好漂亮。有多漂亮呢？为了让人看不清楚，我特地使用了高斯模糊处理了一下</p><hr><p>前面两番已经交代了深度视觉特别是ToF技术的概况，今天来谈一谈ToF具体实现上的大坑（之一，我预感我还会面临最后一个坑）。</p><p>ToF是一把用来测量距离的尺子，造一把尺子的关注点是精度，而造一批尺子关注的是制造精度的分布。</p><hr><p>一把尺子造出来， 如何知道它是准的？有多么不准？不准了怎么办？￼</p><p>这就涉及到标定 &amp; 补偿</p><ul><li>标定，是指出厂前，使用另外一把更准的尺子教新尺子重新做人，标定后会得到一组标定数据</li><li>补偿，是在运行时，利用出厂前的标定数据，实时地对当前原始数据进行算法处理，得到最终的结果</li></ul><p>那么为什么从传感器直接得到的原始数据不能拿来用呢？我也想呀！可我们面对的是裸片，是真实的物理世界，搞不好还有量子效应。</p><p>因为NDA的缘故， 我不能说得太具体￼ 但参考各家公开的文档，基本情况大差不差。</p><p>造成ToF系统产生误差的重要原因是“热”  中医分内热和外热两种，电烙铁也是如此… 热导致电信号（电子、空穴移动）在硅基芯片内的传导时间发生变化，而ToF高度依赖时间测量的精度。 光速大约 30厘米/纳秒， 若要达到厘米级的测距精度，对时间的测量精度不能低于30皮秒级别￼</p><p>然而环境温度的变化， 芯片工作时的温升， 都会导致精度的大规模失准， 特别是像素和像素之间的温差和其它工艺因素的差别会更加劣化这种情况￼</p><p>不同厂家针对器件的特性，都有各自的办法来解决这个问题。有些厂家的的设计比较独到，为批量化自动生产打开了便利之门。</p><p>另外一个造成误差的主要因素是环境光， 虽说相位检测的ToF系统天生具有差分读取结构，但是过强的环境光或者环境光扰动会使得调制信号的信噪比降低。 </p><p>对于这种情况，补偿算法是一方面，加强调制光照明强度，减少曝光时间，以及光学滤镜都是可以尝试的手段。</p><p>当然还有一些其它的因素，有些是特定器件相关的， 有些影响相对较小，这里不再一一熬述￼</p><p>听上去有点儿复杂，实现起来细节也确实很多，但 是可行的。</p><p>我想这就是个机会，将来总会有厂家把这些算法ASIC化，或者有人给出更简单的打包方案，不过目前，我将会来完成这些￼</p><p>毕竟朕是在暴风雨里单日骑行超过400km的人， 老子的目标在很远的地方。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;由于各种事物影响， ToF项目被暂缓了￼， 趁着公司再次搬家的这段时间，重新捡起来。&lt;/p&gt;
&lt;iframe frameborder=&quot;0&quot; src=&quot;https://v.qq.com/txp/iframe/player.html?vid=o1357dpu781&quot; allo
      
    
    </summary>
    
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/categories/ToF/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/tags/ToF/"/>
    
  </entry>
  
  <entry>
    <title>关于ToF 番二</title>
    <link href="http://blog.tensor-robotics.com/archives/78201d81.html"/>
    <id>http://blog.tensor-robotics.com/archives/78201d81.html</id>
    <published>2020-03-22T07:19:30.000Z</published>
    <updated>2020-03-29T08:08:11.287Z</updated>
    
    <content type="html"><![CDATA[<p>书接前文。【关于ToF 番一】</p><p>上回说到ToF的基本概念， 即LED/LD对着场景发射光线，如果场景中有物体反射光线回来，那么我们测定这道光线从发射到被接收的时间间隔， 就能计算出距该离物体的长度为 1/2 * c * t， c是光速。</p><p>举个例子， 如果光线的旅行时间测得为 5ns， 取光速为30万千米每秒， 那么光线总的行走距离就是 300000000 * 0.000000005 = 1.5米， 因为是一来一回再除以二， 就知道有个物体距离接收器0.75米（光源和接收器在同一位置）</p><p><img src="78201d81/measure.png" alt=""></p><hr><p>对于一个直接ToF系统来说，精度和误差均只依赖于对时间的测量精度。</p><p>当然，由于目前的技术限制，使用直接ToF的成本相对较高，单个diode的体积也很大，一般只用于单点或者几个点的方案。对于阵列式的图像ToF系统，使用的是间接ToF方式。 即不直接测量光线往返时间， 而是发射连续的调制光（例如正玄波）， 通过测量相位偏移的方式间接得出ToF。</p><p>初始发射时从正玄波的0度角开始连续发射， 然后接收到光线时， 通过鉴相算法， 得到相位，通过这个相位差以及调制光的频率， 就能算出光线的飞行时间。 真TM高级！ 不过这也引入了一个雷达里的常用术语：maximum unambiguous range。 具体的算法以及处理，本文暂且按下不表，日后分解，下同。</p><p><img src="78201d81/phase.png" alt=""></p><hr><p>虽然降低了难度， 但是也引入更多噪音。 因为测量相移受到诸多因素的影响，例如系统时钟的ppm，传感器温度，物体反射强度，背景光线强度等。</p><p>这回我们就简单说说ToF的工作、设计流程。</p><p>从整个系统看， 首先要考虑的是测距范围问题。 因为光线强度的减弱是距离倒数的平方关系。 例如：期待的测距范围是 5cm ~ 5m， 假如在5cm时的照明输出强度是1的话， 满足5m处同样条件的输出强度得是1000。当然合理的设计光路和LED位置布局， 可以在一定程度上减少功率输出的需求。</p><p>而如果被侧物体中有大量黑体，噗… 是对红外反射率较低的黑色物体， 那么对发射功率的要求又会提高。</p><p>ToF阵列里的每个pixel， 都可以计算出它的振幅质量， 如果过低（欠曝）或者过高（过曝）都无法解析出距离信息， 需要在下一个周期中，进行曝光调整。</p><p>如果需要更高的动态范围， 可以使用各类HDR技术，例如多帧曝光、行间切换曝光等。</p><p>对于曝光时间的选择，还有另外一个问题需要考量，曝光时间越长，就会有越多的环境光被吸收， 这会伤害整体精度（环境光的变化？）。 同时过长的曝光时间， 也会造成帧率降低。 一般曝光时间不要超过1ms，或者可以使用带通滤光片过滤掉调制光频率以外的光线。</p><p>一个典型的ToF计算流程包括：</p><ul><li>多次以不同时长曝光的ToF数据采样（用于鉴相，取得距离数据）</li><li>一次最小曝光时间的灰度数据采集（用于过滤环境光线）</li><li>周期性的传感器片上温度数据读取（用于温度补偿)</li><li>根据算法取出有效数据（过滤掉过曝太多、欠曝过多或者振幅数值过小的数据集）</li><li>温度补偿算法</li><li>背景光补偿算法</li><li>系统常量校准算法</li></ul><hr><p>to be continued</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;书接前文。【关于ToF 番一】&lt;/p&gt;
&lt;p&gt;上回说到ToF的基本概念， 即LED/LD对着场景发射光线，如果场景中有物体反射光线回来，那么我们测定这道光线从发射到被接收的时间间隔， 就能计算出距该离物体的长度为 1/2 * c * t， c是光速。&lt;/p&gt;
&lt;p&gt;举个例子
      
    
    </summary>
    
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/categories/ToF/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/tags/ToF/"/>
    
  </entry>
  
  <entry>
    <title>关于ToF 番一</title>
    <link href="http://blog.tensor-robotics.com/archives/43a03328.html"/>
    <id>http://blog.tensor-robotics.com/archives/43a03328.html</id>
    <published>2020-03-22T06:32:01.000Z</published>
    <updated>2020-03-26T01:33:47.787Z</updated>
    
    <content type="html"><![CDATA[<h2 id="曾经，通过CCD-CMOS等图像阵列传感器以及光学镜头，可以获取一帧帧平面2D的图像。"><a href="#曾经，通过CCD-CMOS等图像阵列传感器以及光学镜头，可以获取一帧帧平面2D的图像。" class="headerlink" title="曾经，通过CCD/CMOS等图像阵列传感器以及光学镜头，可以获取一帧帧平面2D的图像。"></a>曾经，通过CCD/CMOS等图像阵列传感器以及光学镜头，可以获取一帧帧平面2D的图像。</h2><h2 id="现在，日新月异的传感器技术以及强大的移动计算能力，让计算机获得深度感知能力的可能性也越来越多。"><a href="#现在，日新月异的传感器技术以及强大的移动计算能力，让计算机获得深度感知能力的可能性也越来越多。" class="headerlink" title="现在，日新月异的传感器技术以及强大的移动计算能力，让计算机获得深度感知能力的可能性也越来越多。"></a>现在，日新月异的传感器技术以及强大的移动计算能力，让计算机获得深度感知能力的可能性也越来越多。</h2><h2 id="当获得一帧3D深度图景时，会收到一幅2D深度阵列，-其中的每个”pixel”都代表了该点对应物体的实际距离。闭上眼睛想象一下，那是一堆密密麻麻的点云。机器人将更容易的进行自主定位，计算机能更轻易的识别目标，也许新的测量工具，新的交互方式也会应运而生。"><a href="#当获得一帧3D深度图景时，会收到一幅2D深度阵列，-其中的每个”pixel”都代表了该点对应物体的实际距离。闭上眼睛想象一下，那是一堆密密麻麻的点云。机器人将更容易的进行自主定位，计算机能更轻易的识别目标，也许新的测量工具，新的交互方式也会应运而生。" class="headerlink" title="当获得一帧3D深度图景时，会收到一幅2D深度阵列， 其中的每个”pixel”都代表了该点对应物体的实际距离。闭上眼睛想象一下，那是一堆密密麻麻的点云。机器人将更容易的进行自主定位，计算机能更轻易的识别目标，也许新的测量工具，新的交互方式也会应运而生。"></a>当获得一帧3D深度图景时，会收到一幅2D深度阵列， 其中的每个”pixel”都代表了该点对应物体的实际距离。闭上眼睛想象一下，那是一堆密密麻麻的点云。机器人将更容易的进行自主定位，计算机能更轻易的识别目标，也许新的测量工具，新的交互方式也会应运而生。</h2><h2 id="双眼（和大脑）是人类获得深度感知最自然的渠道。通过长在不同地方的两只眼睛￼，视网膜上被投影了两帧“略有差异”的倒影，大脑根据几十年来的习得，分析出这两个影像中相同的物体，以及它们距离我们自身的大致距离。"><a href="#双眼（和大脑）是人类获得深度感知最自然的渠道。通过长在不同地方的两只眼睛￼，视网膜上被投影了两帧“略有差异”的倒影，大脑根据几十年来的习得，分析出这两个影像中相同的物体，以及它们距离我们自身的大致距离。" class="headerlink" title="双眼（和大脑）是人类获得深度感知最自然的渠道。通过长在不同地方的两只眼睛￼，视网膜上被投影了两帧“略有差异”的倒影，大脑根据几十年来的习得，分析出这两个影像中相同的物体，以及它们距离我们自身的大致距离。"></a>双眼（和大脑）是人类获得深度感知最自然的渠道。通过长在不同地方的两只眼睛￼，视网膜上被投影了两帧“略有差异”的倒影，大脑根据几十年来的习得，分析出这两个影像中相同的物体，以及它们距离我们自身的大致距离。</h2><h2 id="这个原理也是计算机目前深度视觉原理的三大流派之一：-双目视觉。-另外两个技术流，一个基于ToF测距技术，-另外一个基于Structured-Light技术。当然这是主要的分类，具体场景，具体产品，可能会相互融合，或者辅以其它技术、算法。"><a href="#这个原理也是计算机目前深度视觉原理的三大流派之一：-双目视觉。-另外两个技术流，一个基于ToF测距技术，-另外一个基于Structured-Light技术。当然这是主要的分类，具体场景，具体产品，可能会相互融合，或者辅以其它技术、算法。" class="headerlink" title="这个原理也是计算机目前深度视觉原理的三大流派之一： 双目视觉。 另外两个技术流，一个基于ToF测距技术， 另外一个基于Structured Light技术。当然这是主要的分类，具体场景，具体产品，可能会相互融合，或者辅以其它技术、算法。"></a>这个原理也是计算机目前深度视觉原理的三大流派之一： 双目视觉。 另外两个技术流，一个基于ToF测距技术， 另外一个基于Structured Light技术。当然这是主要的分类，具体场景，具体产品，可能会相互融合，或者辅以其它技术、算法。</h2><h2 id="此番将大致比较一下这三个技术流的主要特征。-下一更将重点介绍本屌目前正在玩儿的ToF方案原理。"><a href="#此番将大致比较一下这三个技术流的主要特征。-下一更将重点介绍本屌目前正在玩儿的ToF方案原理。" class="headerlink" title="此番将大致比较一下这三个技术流的主要特征。 下一更将重点介绍本屌目前正在玩儿的ToF方案原理。"></a>此番将大致比较一下这三个技术流的主要特征。 下一更将重点介绍本屌目前正在玩儿的ToF方案原理。</h2><hr><h3 id="就双目视觉来说，-对前端硬件特殊性的要求很低，两个普通摄像头即可（或许有同步采样要求）。但要从两张平面图像恢复出原本的深度信息，重建工作对于算力、算法的要求可是相当相当的高。此外对于弱光环境、光线扰动、无特征的面（一堵白墙）都无法很好处理。其速度响应、帧率、可靠性都会多少有问题。至于它的优点嘛。。除了刚刚说的硬件比较便宜外，还有一个就是分辨率理论上可以做得比较高（受限于算力）。"><a href="#就双目视觉来说，-对前端硬件特殊性的要求很低，两个普通摄像头即可（或许有同步采样要求）。但要从两张平面图像恢复出原本的深度信息，重建工作对于算力、算法的要求可是相当相当的高。此外对于弱光环境、光线扰动、无特征的面（一堵白墙）都无法很好处理。其速度响应、帧率、可靠性都会多少有问题。至于它的优点嘛。。除了刚刚说的硬件比较便宜外，还有一个就是分辨率理论上可以做得比较高（受限于算力）。" class="headerlink" title="就双目视觉来说， 对前端硬件特殊性的要求很低，两个普通摄像头即可（或许有同步采样要求）。但要从两张平面图像恢复出原本的深度信息，重建工作对于算力、算法的要求可是相当相当的高。此外对于弱光环境、光线扰动、无特征的面（一堵白墙）都无法很好处理。其速度响应、帧率、可靠性都会多少有问题。至于它的优点嘛。。除了刚刚说的硬件比较便宜外，还有一个就是分辨率理论上可以做得比较高（受限于算力）。"></a>就双目视觉来说， 对前端硬件特殊性的要求很低，两个普通摄像头即可（或许有同步采样要求）。但要从两张平面图像恢复出原本的深度信息，重建工作对于算力、算法的要求可是相当相当的高。此外对于弱光环境、光线扰动、无特征的面（一堵白墙）都无法很好处理。其速度响应、帧率、可靠性都会多少有问题。至于它的优点嘛。。除了刚刚说的硬件比较便宜外，还有一个就是分辨率理论上可以做得比较高（受限于算力）。</h3><h3 id="而Structured-Light呢，翻译过来是“结构光”。-是一种很好玩儿的技术。-最新的Apple-iPhone-X应该就是这个技术的一个变种。"><a href="#而Structured-Light呢，翻译过来是“结构光”。-是一种很好玩儿的技术。-最新的Apple-iPhone-X应该就是这个技术的一个变种。" class="headerlink" title="而Structured Light呢，翻译过来是“结构光”。 是一种很好玩儿的技术。 最新的Apple iPhone X应该就是这个技术的一个变种。"></a>而Structured Light呢，翻译过来是“结构光”。 是一种很好玩儿的技术。 最新的Apple iPhone X应该就是这个技术的一个变种。</h3><h3 id="基于结构光技术的深度系统，有一个主动（红外）光源，像外界投射设计过的点阵，或者干涉条纹或者别的什么pattern。这些pattern光遇到物体反射回摄像头。后端算法会根据这些点在摄像头里的位置推出物体实际的距离。"><a href="#基于结构光技术的深度系统，有一个主动（红外）光源，像外界投射设计过的点阵，或者干涉条纹或者别的什么pattern。这些pattern光遇到物体反射回摄像头。后端算法会根据这些点在摄像头里的位置推出物体实际的距离。" class="headerlink" title="基于结构光技术的深度系统，有一个主动（红外）光源，像外界投射设计过的点阵，或者干涉条纹或者别的什么pattern。这些pattern光遇到物体反射回摄像头。后端算法会根据这些点在摄像头里的位置推出物体实际的距离。"></a>基于结构光技术的深度系统，有一个主动（红外）光源，像外界投射设计过的点阵，或者干涉条纹或者别的什么pattern。这些pattern光遇到物体反射回摄像头。后端算法会根据这些点在摄像头里的位置推出物体实际的距离。</h3><h3 id="结构光技术对算法、算力的要求比起双面视觉来说下降很多。因为是主动投射，对弱光环境下的效果显著提升。但因为需要投影pattern，对超强光下的应用反而是受限的。此外结构光技术的深度系统，只能测定极短-中短距离的物体，搞不远。。。分辨精度在mm-cm级别。"><a href="#结构光技术对算法、算力的要求比起双面视觉来说下降很多。因为是主动投射，对弱光环境下的效果显著提升。但因为需要投影pattern，对超强光下的应用反而是受限的。此外结构光技术的深度系统，只能测定极短-中短距离的物体，搞不远。。。分辨精度在mm-cm级别。" class="headerlink" title="结构光技术对算法、算力的要求比起双面视觉来说下降很多。因为是主动投射，对弱光环境下的效果显著提升。但因为需要投影pattern，对超强光下的应用反而是受限的。此外结构光技术的深度系统，只能测定极短-中短距离的物体，搞不远。。。分辨精度在mm-cm级别。"></a>结构光技术对算法、算力的要求比起双面视觉来说下降很多。因为是主动投射，对弱光环境下的效果显著提升。但因为需要投影pattern，对超强光下的应用反而是受限的。此外结构光技术的深度系统，只能测定极短-中短距离的物体，搞不远。。。分辨精度在mm-cm级别。</h3><h3 id="intel的realsense和老款m-Kinect是代表产品。"><a href="#intel的realsense和老款m-Kinect是代表产品。" class="headerlink" title="intel的realsense和老款m$ Kinect是代表产品。"></a>intel的realsense和老款m$ Kinect是代表产品。</h3><h3 id="传统的固定pattern投影技术，深度分辨率也受到pattern发生器的限制。"><a href="#传统的固定pattern投影技术，深度分辨率也受到pattern发生器的限制。" class="headerlink" title="传统的固定pattern投影技术，深度分辨率也受到pattern发生器的限制。"></a>传统的固定pattern投影技术，深度分辨率也受到pattern发生器的限制。</h3><h3 id="苹果那个就比较牛逼，传说pattern是可变的，分辨精度在极短距离内可以达到惊人的um级别，分辨率在适当的范围内也相对喜人。"><a href="#苹果那个就比较牛逼，传说pattern是可变的，分辨精度在极短距离内可以达到惊人的um级别，分辨率在适当的范围内也相对喜人。" class="headerlink" title="苹果那个就比较牛逼，传说pattern是可变的，分辨精度在极短距离内可以达到惊人的um级别，分辨率在适当的范围内也相对喜人。"></a>苹果那个就比较牛逼，传说pattern是可变的，分辨精度在极短距离内可以达到惊人的um级别，分辨率在适当的范围内也相对喜人。</h3><h3 id="ToF的全称是”Time-of-Flight”。本意是通过测量光线的折返时间来算出距离。我们都知道-距离-速度-×-时间。光速爱因斯坦告诉我们不变了，现在只要测定光线从物体反射回来的时间就能很容易算出距离来了。听上去是不是很酷！要测定一秒绕地球七圈的光，行走很短距离的时间？具体原理和操作，下一弹说￼。"><a href="#ToF的全称是”Time-of-Flight”。本意是通过测量光线的折返时间来算出距离。我们都知道-距离-速度-×-时间。光速爱因斯坦告诉我们不变了，现在只要测定光线从物体反射回来的时间就能很容易算出距离来了。听上去是不是很酷！要测定一秒绕地球七圈的光，行走很短距离的时间？具体原理和操作，下一弹说￼。" class="headerlink" title="ToF的全称是”Time of Flight”。本意是通过测量光线的折返时间来算出距离。我们都知道 距离 = 速度 × 时间。光速爱因斯坦告诉我们不变了，现在只要测定光线从物体反射回来的时间就能很容易算出距离来了。听上去是不是很酷！要测定一秒绕地球七圈的光，行走很短距离的时间？具体原理和操作，下一弹说￼。"></a>ToF的全称是”Time of Flight”。本意是通过测量光线的折返时间来算出距离。我们都知道 距离 = 速度 × 时间。光速爱因斯坦告诉我们不变了，现在只要测定光线从物体反射回来的时间就能很容易算出距离来了。听上去是不是很酷！要测定一秒绕地球七圈的光，行走很短距离的时间？具体原理和操作，下一弹说￼。</h3><h3 id="和结构光一样，ToF同样需要主动发射光线。当然不是“结构”的，它只是亮和暗，视界内全面覆盖。所以功耗会比结构光的大一丢丢，特别是远距离的时候，喔，对了反正结构光也搞不远…"><a href="#和结构光一样，ToF同样需要主动发射光线。当然不是“结构”的，它只是亮和暗，视界内全面覆盖。所以功耗会比结构光的大一丢丢，特别是远距离的时候，喔，对了反正结构光也搞不远…" class="headerlink" title="和结构光一样，ToF同样需要主动发射光线。当然不是“结构”的，它只是亮和暗，视界内全面覆盖。所以功耗会比结构光的大一丢丢，特别是远距离的时候，喔，对了反正结构光也搞不远…"></a>和结构光一样，ToF同样需要主动发射光线。当然不是“结构”的，它只是亮和暗，视界内全面覆盖。所以功耗会比结构光的大一丢丢，特别是远距离的时候，喔，对了反正结构光也搞不远…</h3><h3 id="新款m-Kinect是这个架构的代表。"><a href="#新款m-Kinect是这个架构的代表。" class="headerlink" title="新款m$ Kinect是这个架构的代表。"></a>新款m$ Kinect是这个架构的代表。</h3><h3 id="ToF技术架构的优势之一就是计算相对最简单，几乎是传感器直接测量。帧率高并因此响应极快。抗外界光线干扰能力很强。长、短距离皆可应用。分辨精度在mm～cm级别之间。"><a href="#ToF技术架构的优势之一就是计算相对最简单，几乎是传感器直接测量。帧率高并因此响应极快。抗外界光线干扰能力很强。长、短距离皆可应用。分辨精度在mm～cm级别之间。" class="headerlink" title="ToF技术架构的优势之一就是计算相对最简单，几乎是传感器直接测量。帧率高并因此响应极快。抗外界光线干扰能力很强。长、短距离皆可应用。分辨精度在mm～cm级别之间。"></a>ToF技术架构的优势之一就是计算相对最简单，几乎是传感器直接测量。帧率高并因此响应极快。抗外界光线干扰能力很强。长、短距离皆可应用。分辨精度在mm～cm级别之间。</h3><h3 id="缺陷除了刚刚提到的功耗外，分辨率是最大硬伤。目前-320x240算旗舰，640x480等更高规格器件或许在路线图上"><a href="#缺陷除了刚刚提到的功耗外，分辨率是最大硬伤。目前-320x240算旗舰，640x480等更高规格器件或许在路线图上" class="headerlink" title="缺陷除了刚刚提到的功耗外，分辨率是最大硬伤。目前~320x240算旗舰，640x480等更高规格器件或许在路线图上"></a>缺陷除了刚刚提到的功耗外，分辨率是最大硬伤。目前~320x240算旗舰，640x480等更高规格器件或许在路线图上</h3><h3 id="未来的道路在哪里？谁知道呢。。。走着瞧吧。。。"><a href="#未来的道路在哪里？谁知道呢。。。走着瞧吧。。。" class="headerlink" title="未来的道路在哪里？谁知道呢。。。走着瞧吧。。。"></a>未来的道路在哪里？谁知道呢。。。走着瞧吧。。。</h3><h3 id="客户需求-成本控制-正确的技术路线"><a href="#客户需求-成本控制-正确的技术路线" class="headerlink" title="客户需求 + 成本控制 + 正确的技术路线"></a>客户需求 + 成本控制 + 正确的技术路线</h3><h3 id="听说把握好这三点，就能实现财务自由￼￼￼￼"><a href="#听说把握好这三点，就能实现财务自由￼￼￼￼" class="headerlink" title="听说把握好这三点，就能实现财务自由￼￼￼￼"></a>听说把握好这三点，就能实现财务自由￼￼￼￼</h3><h3 id="而我呢，目前能抓住一个半就好￼"><a href="#而我呢，目前能抓住一个半就好￼" class="headerlink" title="而我呢，目前能抓住一个半就好￼"></a>而我呢，目前能抓住一个半就好￼</h3><h3 id="to-be-continued"><a href="#to-be-continued" class="headerlink" title="to be continued"></a>to be continued</h3><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;曾经，通过CCD-CMOS等图像阵列传感器以及光学镜头，可以获取一帧帧平面2D的图像。&quot;&gt;&lt;a href=&quot;#曾经，通过CCD-CMOS等图像阵列传感器以及光学镜头，可以获取一帧帧平面2D的图像。&quot; class=&quot;headerlink&quot; title=&quot;曾经，通过C
      
    
    </summary>
    
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/categories/ToF/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="ToF" scheme="http://blog.tensor-robotics.com/tags/ToF/"/>
    
  </entry>
  
  <entry>
    <title>Python ctypes的使用实例</title>
    <link href="http://blog.tensor-robotics.com/archives/b396a14c.html"/>
    <id>http://blog.tensor-robotics.com/archives/b396a14c.html</id>
    <published>2020-03-22T03:17:56.000Z</published>
    <updated>2020-03-29T08:13:50.220Z</updated>
    
    <content type="html"><![CDATA[<p>Python中可以使用ctypes模块方便的调用C代码写的库， 而无须对C代码有任何多余的要求。</p><p>此仅列一例，权做记录。</p><hr><p><img src="b396a14c/ls.png" alt=""></p><p>首先有两个文件， C和对应的头文件。</p><p>在people.c中， 有三个非常简单的函数。 供日后调用。<br>而在people.h中， 是对应的函数声明， 在此不表。</p><p><img src="b396a14c/source.png" alt=""></p><hr><p>接下来的一步， 将这个C代码编译成库， 使用如下的命令<br><img src="b396a14c/compile.png" alt=""></p><p>这将生成一个叫 libpeople.so的库， 和平常编译库的方式完全一样。</p><hr><p>最后， 激动人心的时刻—-直接在python中调用这个C库。<br><img src="b396a14c/call.png" alt=""></p><p>进入ipython后， 首当其冲import ctypes， 然后用cdll里的LoadLibrary导入刚刚生成的库。</p><p>因为make_people使用了自定义的struct和指针， 所以需要现在Python里先建立对于的数据结构。</p><p>之后就能随心所欲的调用c库里的函数了。</p><hr><p>一些说明。<br>库导入后本身没有动态性， 也就是说在ipython里， 输入完mylib.之后，按tab键是不能自动补全所有的function的，但是手工输入一次之后， 还是能看到已经有的东西。</p><p>因为Python的脚本性， 如果C库没有做好类型检查，特别是指针相关的，而发生致命错误的，在Python动态运行时， Python解析器进程会崩溃。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Python中可以使用ctypes模块方便的调用C代码写的库， 而无须对C代码有任何多余的要求。&lt;/p&gt;
&lt;p&gt;此仅列一例，权做记录。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&quot;b396a14c/ls.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;首先有两个文件， C和对应的头
      
    
    </summary>
    
    
      <category term="CS" scheme="http://blog.tensor-robotics.com/categories/CS/"/>
    
    
      <category term="生产和分享知识" scheme="http://blog.tensor-robotics.com/tags/%E7%94%9F%E4%BA%A7%E5%92%8C%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86/"/>
    
      <category term="Python" scheme="http://blog.tensor-robotics.com/tags/Python/"/>
    
      <category term="ctypes" scheme="http://blog.tensor-robotics.com/tags/ctypes/"/>
    
  </entry>
  
  <entry>
    <title>the first blog</title>
    <link href="http://blog.tensor-robotics.com/archives/ef0a297a.html"/>
    <id>http://blog.tensor-robotics.com/archives/ef0a297a.html</id>
    <published>2020-03-19T12:00:01.000Z</published>
    <updated>2020-04-08T09:27:23.557Z</updated>
    
    <content type="html"><![CDATA[<p>安定了。<br>以后在考虑建个电报channel。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;安定了。&lt;br&gt;以后在考虑建个电报channel。&lt;/p&gt;
&lt;script&gt;
        document.querySelectorAll(&#39;.github-emoji&#39;)
          .forEach(el =&gt; {
            if (!el.
      
    
    </summary>
    
    
      <category term="misc" scheme="http://blog.tensor-robotics.com/categories/misc/"/>
    
    
      <category term="misc" scheme="http://blog.tensor-robotics.com/tags/misc/"/>
    
      <category term="test" scheme="http://blog.tensor-robotics.com/tags/test/"/>
    
  </entry>
  
</feed>
